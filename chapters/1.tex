% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../arsclassica.tex
% !TEX spellcheck = it-IT

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Continuos time \bn{}}
\label{cap:ctbn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acresetall
In questo capitolo si introducono i concetti fondamentali relativi alle \ac{CTBN}. Le \acs{CTBN} sono un framework capace di modellare processi stocastici a tempo continuo e con spazio degli stati discreto.

Prima di affrontare tale argomento si presentano alcuni concetti propedeutici a questo lavoro di tesi: le \ac{BN} e i \mprocess{} (\autoref{sec:fondamenti}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fondamenti}
\label{sec:fondamenti}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Le \acl{CTBN} utilizzano concetti e idee provenienti da teorie afferenti l'area statistica e del machine learning. Al fine di conferire alla discussione sulle \acs{CTBN} un quadro iniziale completo ed esauriente, si presentano quindi gli aspetti di maggior rilievo di tali argomenti.
\begin{description}
\item[\bn{}] \hfill \\
Le \acl{CTBN} utilizzano una rappresentazione strutturata dello spazio degli stati propria della teoria delle \acl{BN}. Ne ereditano perciò gli aspetti chiave (\eg{} indipendenza \cond*{}) nonché l'insieme delle tecniche algoritmiche per l'apprendimento e l'inferenza.
\item[Processi di Markov]\label{sec:fondamenti-mp}\hfill \\
Le \acl{CTBN} descrivono la dinamica evolutiva di variabili casuali tramite un costituito da un insieme di \mprocess{} \cond{}.
\end{description}

\subsection{\bn{}}\label{subsec:bn}
Una \acl{BN} è un modello grafico probabilistico costituito da un \acf{DAG}\footnote{\label{note:DAG}Un grafo aciclico orientato (anche detto grafo aciclico diretto o digrafo aciclico) è un tipo di grafo che non ammette cicli ed i cui archi sono orientati: comunque si scelga un vertice non è possibile tornare ad esso percorrendo gli archi del grafo.}. I nodi di tale grafo rappresentano un insieme di variabili casuali mentre gli archi evidenziano le dipendenze (e le indipendenze) condizionali fra esse~\citep{Korb2011}.
Una \acs{BN} rappresenta la distribuzione di probabilità congiunta del suo insieme di variabili casuali tramite la distribuzione di probabilità \cond*{} di ognuna di essa (si veda l'\autoref{eq:bn-chain-rule}).
Le \acs{BN} sono quindi modelli grafico probabilistici con cui è possibile modellare in modo probabilistico le relazioni causali tra variabili. Esse risultano molto utili nella rappresentazione e analisi di domini caratterizzati da incertezza. Sono infatti usate in svariate applicazioni di supporto alle decisioni, bioinformatica, biologia computazionale, data mining, information retrieval e \keyword{classificazione}.

\subsubsection{Rappresentazione}\label{subsec:bn-representation}
Di seguito si fornisce la definizione formale delle \keywordsub[definizione]{\acl{BN}} e si introducono i loro aspetti basilari.

\begin{definizione}[\acl{BN}]
\label{defn:bn}
Una \acl{BN} $\conceptsym{B}$ è una coppia $\conceptsym{B}=(\conceptsym{G},\param{$\theta$}_{\conceptsym{G}})$ costituita da:
\begin{itemize}
    \item $\conceptsym{G}=(\set{V}(\conceptsym{G}),\set{A}(\conceptsym{G}))$, un \acl{DAG} dove:
    \begin{itemize}
        \item $\set{V}(\conceptsym{G})=\{\setel{V_1}, \dotsc, \setel{V_n}\}$ è l'insieme dei nodi, ognuno dei quali è associato ad una \acf{CPD}\footnote{Nel caso di variabili causali discrete, le \acs{CPD} sono rappresentabili come delle tabelle che contengono i valori di probabilità di un nodo in funzione di tutte le possibili configurazioni dei nodi genitori (cioè l'insieme dei nodi da cui parte un arco che punta al nodo di interesse). Tali tabelle sono spesso chiamate \acf{CPT}.}
        \item $\set{A}(\conceptsym{G})\subseteq\set{V}(\conceptsym{G})\times\set{V}(\conceptsym{G})$ è l'insieme degli archi fra i nodi $\set{V}(\conceptsym{G})$
    \end{itemize}
    \item $\param{$\theta$}_{\conceptsym{G}}$, insieme delle \acs{CPD} dei nodi che specifica $\set{P}_{\conceptsym{B}}$, la distribuzione di probabilità congiunta delle variabili casuali $\set{X}_{\set{V}(\conceptsym{G})}$ a cui corrispondono i nodi $\set{V}(\conceptsym{G})$.
\end{itemize}
\end{definizione}
\begin{osservazione}\label{oss:bn-markov-assumption}
Ogni nodo di una \acs{BN} è condizionalmente indipendente (si veda \autoref{defn:ic}) dai suoi non--discendenti dati i suoi nodi genitori.
\end{osservazione}

La \acs{CPD} di ogni variabile casuale $\setel{X_i}\in\set{X}_{\set{V}(\conceptsym{G})}$ esprime i suoi valori di probabilità in funzione dei valori assunti da $Pa(\setel{X_i})$, notazione con cui si denota l'\emph{insieme dei nodi genitori} per ogni nodo o variabile casuale.

Un arco da un nodo genitore verso un nodo figlio di $\conceptsym{G}$ rappresenta una dipendenza diretta fra le corrispettive variabili casuali~\citep[si veda][sezione 14.1]{Russel2003}. I nodi non direttamente connessi rappresentano variabili casuali condizionalmente indipendenti dagli altri nodi (per quanto riguarda il concetto di \emph{indipendenza \cond*{}} si rimanda alla \autoref{defn:ic}).

Prima di procedere con la discussione si introduce la Chain Rule, proprietà fondamentale delle \acs{BN}.

\begin{teorema}[Chain Rule]
Dato un insieme di variabili casuali e una distribuzione di probabilità congiunta definita su di esse è possibile calcolare qualsiasi elemento di tale distribuzione tramite le distribuzioni di probabilità \cond*{} delle variabili casuali.
\end{teorema}

Perciò, dato un insieme di variabili casuali $\setel{A_1},\dotsc,\setel{A_n}$ è possibile calcolare il valore di tale membro della distribuzione di probabilità congiunta applicando la definizione di probabilità \cond*{}:
\[
\set{P}(\setel{A_1},\dotsc,\setel{A_n})=\set{P}(\setel{A_n}\,\arrowvert\,\setel{A_{n-1}},\dotsc,\setel{A_1})\cdot\set{P}(\setel{A_{n-1}},\dotsc,\setel{A_1})\text{.}
\]
Ripetendo tale processo per ogni termine finale si ottiene:
\begin{equation}
\label{eq:chain-rule}
\set{P}\big(\bigcap_{k=1}^{n}\setel{A_k}\big)=\prod_{k=1}^{n}\set{P}\big(\setel{A_k}\,\arrowvert\,\bigcap_{j=1}^{k-1}\setel{A_j}\big)\text{.}
\end{equation}

Applicando l'\autoref{eq:chain-rule} alle \acl{BN} si dice che la distribuzione di probabilità congiunta $\set{P}_{\conceptsym{B}}$ si \emph{fattorizza} rispetto al grafo $\conceptsym{G}$ se è possibile scrivere:
\begin{equation}\label{eq:bn-chain-rule}
\set{P}_{\conceptsym{B}}(\setel{X_1}, \dotsc, \setel{X_n})=\prod_{i=1}^{n}\set{P}(\setel{X_i}\,\arrowvert\,Pa(\setel{X_i}))\text{.}
\end{equation}
L'\autoref{eq:bn-chain-rule} esprime quindi la \emph{proprietà di fattorizzazione} della distribuzione congiunta del modello grafico, detta \emph{distribuzione di probabilità globale}, ed è ciò che permette di descriverla efficientemente in funzione delle distribuzioni condizionali dei nodi~\citep[][sezione 14.2]{Russel2003}, dette \emph{distribuzioni di probabilità locali}. Questa proprietà contiene in sè il concetto di \emph{proprietà di Markov} (si veda la \autoref{defn:markov-assumption}), il quale attesta che ogni nodo di una \acl{BN} dipende solo ed esclusivamente dai suoi nodi genitori~\citep[][sottosezione 2.2.4]{Korb2011}. Si noti inoltre, che le \acl{BN} richiedono (\acs{DAG}, \autoref{defn:bn}) che la loro componente $\conceptsym{G}$ non contenga cicli  affinché possano rispettare tale proprietà~\citep[][sezione 14.1]{Russel2003}.

Poiché, come detto, una \acl{BN} stabilisce che ogni nodo, dati i suoi genitori, è \emph{condizionalmente indipendente} da ogni altro nodo che non sia un suo discendente, di seguito si introduce tale concetto formalmente.
\begin{definizione}[Indipendenza \cond*{}]\label{defn:ic}
Un evento $\setel{A}$ è \emph{condizionalmente indipendente} da un evento $\setel{B}$, data l'evidenza su un evento $\setel{C}$, qualora la conoscenza di $\setel{B}$ non apporta alcuna variazione alla probabilità di $\setel{A}$ rispetto a quella conseguente alla conoscenza di $\setel{C}$.
Formalmente, ciò significa che:
\[
\set{P}(\setel{A},\setel{B}\,\arrowvert\,\setel{C})=\set{P}(\setel{A}\,\arrowvert\,\setel{B},\setel{C})\cdot\set{P}(\setel{B}\,\arrowvert\,\setel{C})=\set{P}(\setel{A}\,\arrowvert\,\setel{C})\cdot\set{P}(\setel{B}\,\arrowvert\,\setel{C})\text{.}
\]
Da cui segue che:
\[
\setel{A}\perp\setel{B}\,\arrowvert\,\setel{C}\iff\set{P}(\setel{A}\,\arrowvert\,\setel{B},\setel{C})=\set{P}(\setel{A}\,\arrowvert\,\setel{C})\text{.}
\]
\end{definizione}
In termini non formali, supponendo di essere nel caso della definizione, cioè di avere una variabile casuale $\setel{A}$ \emph{condizionalmente indipendente} da $\setel{B}$ dato $\setel{C}$, ciò significa che è possibile ignorare $\setel{B}$ poiché essa non ha alcun riflesso sulla distribuzione \cond*{} di $\setel{A}$ quando sia noto l'evento $\setel{C}$.

Si noti che il concetto appena espresso gioca un ruolo importante per i modelli probabilistici, quali sono le \acl{BN}, semplificando i calcoli richiesti per l'inferenza e l'apprendimento. Le \acl{BN} ereditano questi benefici dell'indipendenza \cond*{} come conseguenza della loro definizione (si veda l'\autoref{oss:bn-markov-assumption}). Infatti, la distribuzione \cond*{} di ogni variabile casuale $\setel{X_i}$ dipende solo ed esclusivamente dal valore dei suoi genitori, $Pa(\setel{X_i})$, mentre ignora completamente i valori dei nodi che non discendono da essa, $Nd(\setel{X_i})$.

Grazie alla \autoref{defn:ic} è possibile esprimere in modo formale il concetto appena espresso per ogni nodo $\setel{X_i}\in\set{X}_{\set{V}(\conceptsym{G})}$:
\[
\set{P}(\setel{X_i}\,\arrowvert\,\setel{E},Pa(\setel{X_i}))=\set{P}(\setel{X_i}\,\arrowvert\,Pa(\setel{X_i})) \quad \forall\:\setel{E}\in Nd(\setel{X_i})\text{,}
\]
dove $Nd(\setel{X_i})$ è l'insieme dei nodi non--discendenti (ed $\setel{E}$ è una variabile casuale o un insieme di variabili casuali ad essi associati).
In base a ciò si dice quindi che le \acl{BN} rispettano l'\emph{assunzione locale di Markov}.

\subsubsection{Apprendimento e Inferenza}\acresetall
In questa sezione si descrivono brevemente e a scopo introduttivo i processi di apprendimento e inferenza sulle \acl{BN}.

Il problema dell'apprendimento per le \acl{BN} si divide principalmente in due casi:
\begin{itemize}
    \item apprendere le \acs{CPD}, nota la struttura
    \item apprendere sia le \acs{CPD}, sia la struttura (incognita).
\end{itemize}
In entrambi i casi è di grande aiuto la rappresentazione efficiente delle \acl{BN} che, tramite la \emph{fattorizzazione} della distribuzione di probabilità congiunta, permette di rappresentarla in modo compatto (tramite l'\autoref{eq:bn-chain-rule}) riducendo notevolmente il numero di parametri da calcolare.

Come detto, per specificare completamente una \acl{BN} è necessario rappresentare completamente la distribuzione di probabilità congiunta delle sue variabili tramite la \acl{CPD} di ognuna di esse. In generale, tali distribuzioni condizionali possono avere una qualsiasi forma anche se, al fine di semplificare i calcoli, è comune utilizzare distribuzioni discrete o Gaussiane per modellarle. Nel caso in cui i dati siano parzialmente osservabili solitamente si procede tramite l'algoritmo di \acf{EM}, il quale alterna il calcolo dei valori attesi delle variabili casuali non osservate condizionalmente ai dati osservati con la massimizzazione della likelihood. Tale approccio generalmente converge ai valori di massima probabilità a posteriori per i parametri~\citep[si veda][]{Dempster1977}.

Per l'\emph{apprendimento dei parametri} esistono comunque una varietà di altri approcci possibili~\citep[si veda][]{Heckerman1996} (\eg{} trattare i parametri come variabili casuali sconosciute addizionali) che tuttavia non sono argomento di questo lavoro di tesi.

Si noti che le \acl{BN} non sono solamente un \emph{modello discriminativo ma anche generativo} poiché possono essere utilizzate per soddisfare query arbitrarie, cioè per effettuare \emph{inferenza probabilistica}: calcolare la distribuzione a posteriori di un insieme di variabili casuali data l'osservazione (evidenza) di altre (sfruttando il \emph{teorema di Bayes}). In letteratura~\citep[si veda][]{Heckerman1996} sono stati esplorati molti metodi di \emph{inferenza esatta}, quali ad esempio l'eliminazione tramite integrazione o somma delle variabili non osservate che non fanno parte della query probabilistica o il metodo \emph{clique tree propagation}. Questi metodi, come gli altri presenti in letteratura, sono sempre esponenziali rispetto al \emph{tree-width}\footnote{In teoria dei grafi, il \emph{tree-width} è un numero associato ad un grafo. Esso corrisponde alla lunghezza minima di tutti i possibili alberi di decomposizione del grafo in esame. La lunghezza di un albero di decomposizione corrisponde alla dimensione massima dei suoi nodi, cioè sottoinsiemi dell'insieme dei vertici del grafo, sottratto $1$.} del grafo. Per quanto riguarda invece gli algoritmi di \emph{inferenza approssimata} si citano due tra i più comuni: l'\emph{importance sampling}~\citep{Shachter1990} e i metodi \acf{MCMC} (\emph{Gibbs sampling}, \emph{Metropolis sampling}, e \emph{Hybrid Monte Carlo sampling}), basati sul campionamento stocastico~\citep[si veda][]{Geman1984,Gilks1996,MacKay1998}.

Nel caso in cui non si disponga della struttura di una \acs{BN} è richiesto l'\emph{apprendimento strutturale}. Gli algoritmi per l'apprendimento strutturale delle \acl{BN} possono essere divisi in due famiglie.
\begin{description}
    \item[Algoritmi basati su vincoli] \hfill \\
    Algoritmi che apprendono la struttura del grafo analizzando le relazioni probabilistiche derivanti dalla proprietà di Markov tramite test di indipendenza condizionale e costruendo un grafo che soddisfi le proprietà di \emph{d-separazione}\footnote{Concetto di separazione direzionale tra insiemi di nodi collegato al concetto di \emph{indipendenza condizionale}. Ad esempio, quando un insieme di nodi $\set{E}$ \emph{d-separa} un insieme di nodi $\set{X}=\{\,\setel{A}\,,\,\setel{B}\,\}$ allora $\setel{A}$ e $\setel{B}$ sono condizionalmente indipendenti dato $\set{E}$.} corrispondenti. I modelli risultanti sono spesso interpretati come \emph{modelli causali}~\citep{Pearl1988}.
    \item[Algoritmi basati su punteggio] \hfill \\
    Algoritmi che assegnano un punteggio (tramite una funzione di scoring) a tutte le strutture candidate e utilizzando tecniche di ottimizzazione cercano di raggiungere il punteggio massimo. Gli algoritmi di ricerca \emph{greedy} sono la scelta più comune, tuttavia qualsiasi procedura di ricerca può essere usata.
\end{description}

Gli \emph{algoritmi basati su vincoli} sono basati sull'algoritmo \acf{IC} di~\citet{Verma1991} che fornisce un contesto teorico finalizzato all'apprendimento delle strutture dei modelli causali. L'algoritmo \acs{IC} può essere riassunto nei tre passi successivi.
\begin{itemize}
    \item Apprendimento dello scheletro (\ie{} grafo non diretto) della rete. Poiché la ricerca esaustiva non è, nella maggior parte dei casi, computazionalmente realizzabile, tutti gli algoritmi di apprendimento restringono la ricerca al \emph{Markov blanket}\footnote{\label{note:markov-blanket}Il \emph{Markov blanket} di un nodo $\setel{A}$ è un insieme composto dai nodi genitori di $\setel{A}$, dai suoi nodi figli e da tutti i nodi che condividono un figlio con $\setel{A}$.} di ogni nodo.
    \item Impostare la direzione degli archi che fanno parte di una \emph{v-structure}\footnote{Una \emph{v-structure} è una tripla di nodi $\setel{X}_j\rightarrow\setel{X}_i\leftarrow\setel{X}_k$ incidenti su una connessione convergente.}.
    \item Impostare la direzione degli archi fra i nodi rimanenti affinché il vincolo di aciclicità sia rispettato.
\end{itemize}

Gli \emph{algoritmi basati su punteggio} sono invece delle applicazioni dei vari algoritmi di ricerca euristica (\eg{} \emph{hill climbing}, \emph{tabu search}, \emph{best first search}, \emph{simulated annealing}) che utilizzano una funzione di \emph{scoring}. Solitamente la funzione di \emph{scoring} è basata sulla \emph{likelihood}, ovvero sulla la probabilità a posteriori dell'insieme dei dati di apprendimento (\ie{} \emph{\keyword{\trs{}}}), data la struttura in esame e i parametri del modello. Tale funzione è spesso \emph{score-equivalent}, affinché reti che definiscono la stessa distribuzione di probabilità abbiano lo stesso score~\citep{Chickering2013}. Tuttavia, per quanto questi algoritmi siano utilizzati molto frequentemente, essi sono esponenziali rispetto al numero di nodi della struttura del grafo. Inoltre, qualora si utilizzi una strategia di ricerca locale, è probabile che l'algoritmo restituisca come risultato un minimo locale. Si fa notare che è possibile ridurre il tempo necessario richiesto per l'apprendimento strutturale fissando un numero massimo di genitori candidati e cercando esaustivamente in insiemi di tale cardinalità una struttura che massimizzi l'informazione mutua fra variabili~\citep[][]{Heckerman1995}.

\subsection{Processi di Markov}
\label{subsec:mps}

Sempre al fine di preparare la discussione delle \acl{CTBN} si prosegue presentando alcuni concetti propedeutici relativi ai \mprocess{}, una categoria di processi stocastici con assenza di memoria~\citep{Loeve1978}.

\begin{definizione}[Proprietà di Markov]
\label{defn:markov-assumption}
Secondo la proprietà di Markov gli stati futuri di un processo stocastico sono indipendenti dagli stati passati, avendo evidenza sullo stato presente di tale processo.

Formalmente, un processo stocastico $\setel{X}$ gode di tale proprietà, se e solo se vale la seguente equazione~\citep{Loeve1978}:
\begin{equation}
\label{eq:markov-assumption}
\set{P}(\setel{X}(t + \Delta t)\,\arrowvert\,\setel{X}(t),\,\setel{X}(s))=\set{P}(\setel{X}(t + \Delta t)\,\arrowvert\,\setel{X}(t))\text{,}
\end{equation}
per ogni $s$, e $t$ tali che $s < t < \infty$.

I modelli che rispettano tale proprietà sono detti modelli che rispettano l'\emph{assunzione di Markov}.
\end{definizione}

Di conseguenza la \acl{CPD} degli stati futuri di un processo stocastico che gode di tale proprietà è indipendente dagli stati passati dato quello attuale.

In altri termini ciò indica che lo stato futuro di una variabile casuale è \emph{condizionalmente indipendente} (si veda la \autoref{defn:ic}) dalla sequenza dei suoi stati passati, avendo evidenza sul suo stato presente.

Dalla proprietà di Markov deriva la definizione dei \mprocess{}.

\begin{definizione}[\upcase\mprocess*{}]
Si definisce~\citep{Loeve1978} come \mprocess*{} un processo stocastico che gode della proprietà di Markov.
\end{definizione}

\begin{definizione}[Catena di Markov]
Un \mprocess*{} che può assumere solo un numero finito di stati è solitamente definito come una \emph{catena di Markov}~\citep[si veda][10]{Norris1998}.
\end{definizione}

Esistono due tipi di processi di Markov: omogenei e non. Si procede quindi fornendone le definizioni.

\begin{definizione}[\upcase\mprocess*{} \omog*{}]
\label{defn:homogeneus-markov-process}
Un \mprocess*{} è detto \emph{\omog*{}} qualora $\set{P}(\setel{X}(t + \Delta t)\,\arrowvert\,\setel{X}(t))$ non dipenda dal tempo $t$. Affinché ciò sia vero deve risultare che:
\begin{equation}
\label{eq:homogeneus-markov-process}
\set{P}(\setel{X}(t + \Delta t)\,\arrowvert\,\setel{X}(t))=\set{P}(\setel{X}(\Delta t)\,\arrowvert\,\setel{X}(0))\text{.}
\end{equation}
\end{definizione}
Data quindi una variabile casuale $\setel{X}$ e l'insieme delle sue istanziazioni $val(\setel{X})=\{\,\vectel{x}_1\,,\,\dotsc\,,\,\vectel{x}_J\,\}$, $\setel{X}(t)$ è un processo di Markov \emph{omogeneo, a tempo continuo e stati finiti} se e solo se la sua dinamica è definibile in termini di:
\begin{itemize}
    \item una distribuzione di probabilità iniziale $\priorsign{\set{X}}$ su $val(\setel{X})$
    \item una \im*{} $\imsign{\setel{X}}$.
\end{itemize}

\begin{definizione}[\upcase\im*{}]
\label{defn:im}
Una \acf{IM}, rappresenta un \emph{modello di transizione Markoviano}:
\[
\imsign{\setel{X}}=
\begin{bmatrix}
    -\param{q}_{\setel{x}_1}            & \param{q}_{\setel{x}_1\setel{x}_2}    & \cdots & \param{q}_{\setel{x}_1\setel{x}_K}   \\[0.5em]
    \param{q}_{\setel{x}_2\setel{x}_1}  & -\param{q}_{\setel{x}_2}              & \cdots & \param{q}_{\setel{x}_2\setel{x}_K}   \\[0.5em]
    \vdots                              & \vdots                                & \ddots & \vdots                               \\[0.5em]
    \param{q}_{\setel{x}_K\setel{x}_1}  & \param{q}_{\setel{x}_K\setel{x}_2}    & \cdots & -\param{q}_{\setel{x}_K}
\end{bmatrix}\text{.}
\]
Lo scopo di un \im*{} è descrivere il comportamento transiente di $\setel{X}$, un \mprocess*{} \omog*{}.
\end{definizione}
\begin{osservazione}
L'\emph{ordine} di una matrice di intensità corrisponde a $K=|val(\setel{X})|\,$, la cardinalità dell'insieme dei valori assunti da $\setel{X}$.
\end{osservazione}
% \begin{osservazione}\label{oss:squared-im}
% Nel caso in cui $k=2$, la \im*{} $\imsign{\setel{X}}$ è quindi una matrice $2\times2$. Di conseguenza, poiché ogni riga di $\imsign{\setel{X}}$ somma a $0$ per definizione, le \emph{\virgolette{probabilità istantanee}} di transizione fra gli stati di $\setel{X}$ sono sempre pari a $1$.
% \end{osservazione}
Affinché $\imsign{\setel{X}}$ sia una \acl{IM} valida, ogni sua riga deve sommare a $0$:
\[
\param{q}_{\setel{x}_i}=\sum_{i \neq j}\param{q}_{\setel{x}_i\setel{x}_j}\quad\text{con}\quad \param{q}_{\setel{x}_i}\,,\,\param{q}_{\setel{x}_i\setel{x}_j}>0\text{.}
\]

Data quindi una \im*{} $\imsign{\setel{X}}$ essa descrive il comportamento transiente di $\setel{X}(t)$. Se $\setel{X}(0)=\setel{x}_i$, allora il \mprocess*{} \omog*{} (e indicizzato dal tempo $t$) $\setel{X}(t)$ rimarrà nello stato $\setel{x}_i$ una quantità di tempo \emph{esponenzialmente distribuita} rispetto al parametro $\param{q}_{\setel{x}_i}$. Di conseguenza la \emph{funzione di densità} $f$ e la corrispondente \emph{funzione di ripartizione}\footnote{Nel calcolo delle probabilità la funzione di ripartizione di una variabile casuale $\setel{X}$ a valori reali, anche nota come funzione di distribuzione cumulativa, è la funzione che associa a ciascun valore $\setel{x}$ la probabilità che $\setel{X}$ assuma valori minori o uguali ad $\setel{x}$ (\ie{} $\set{P}(\setel{X} \le \setel{x})$).} $F$ sono quelle della distribuzione esponenziale:
\begin{equation}
\label{eq:im-distrib}
\begin{split}
f(t) &= \param{q}_{\setel{x}_i}\,e^{-\param{q}_{\setel{x}_i}t}\,,\quad t>0 \\
F(t) &= 1-e^{-\param{q}_{\setel{x}_i}t}\,,\quad t\geq0\text{.}
\end{split}
\end{equation}

Quando un modello di transizione è definito esclusivamente tramite una \im*{} $\imsign{\setel{X}}$ si dice che esso usa una \emph{parametrizzazione \keywordsub[parametrizzazione]{pura}} delle intensità. In tal caso i parametri per un \mprocess*{} \omog*{} con $K$ stati sono $\{\,\param{q}_{\setel{x}_i}\,,\param{q}_{\setel{x}_i\setel{x}_j} : 1 \leq i\,,j \leq K\,,i \neq j\,\}$.

Mentre gli elementi sulla diagonale di una \im*{}, $\param{q}_{\setel{x}_i}$, codificano una quantità che può essere interpretata come la \emph{\virgolette{probabilità istantanea}} che $\setel{X}$ abbandoni lo stato $\setel{x}_i$, gli elementi non sulla diagonale, $\param{q}_{\setel{x}_i\setel{x}_j}$, esprimono l'\emph{intensità di transizione} dallo stato $\setel{x}_i$ allo stato $\setel{x}_j$.

Tuttavia, questa non è l'unica parametrizzazione possibile per un \mprocess*{} \omog*{}. Si noti infatti che la distribuzione di probabilità locale sulle transizioni di $\setel{X}$ è fattorizzata in due parti.
\begin{definizione}[Parametrizzazione mista delle intensità]\label{defn:mixed-parametrization}
La \emph{parametrizzazione \keywordsub[parametrizzazione]{mista}} delle intensità per un \mprocess*{} \omog*{} $\setel{X}$ con $K$ stati è composta da due insiemi di parametri:
\begin{equation}
\begin{split}
\param{q}_{\setel{X}} &= \{\, \param{q}_{\setel{x}_i} : 1 \leq i \leq K \,\} \text{,} \nonumber\\
\param{$\theta$}_{\setel{X}} &= \{\, \param{$\theta$}_{\setel{x}_i\setel{x}_j} : 1 \leq i\,,j \leq K\,,i \neq j \,\} \text{.}
\end{split}
\end{equation}
La semantica di tali insiemi di parametri è la seguente:
\begin{itemize}
    \item $\param{q}_{\setel{X}}$ è un insieme di intensità $\param{q}_{\setel{x}_i}$ che parametrizzano una \emph{distribuzione di probabilità \keywordsub[distribuzione]{esponenziale}} ed esprimono quando avvengono le transizioni
    \item $\param{$\theta$}_{\setel{X}}$ è un insieme di probabilità $\param{$\theta$}_{\setel{x}_i\setel{x}_j}$ che rappresentano la \emph{probabilita di transitare} dallo stato $\setel{x}_i$ allo stato $\setel{x}_j$, con $i \neq j$, sapendo che avverrà un salto ad un determinato istante di tempo.
\end{itemize}
\end{definizione}
% Perciò:
% \begin{itemize}
%     \item $\param{q}_{\setel{x}_i}$, che esprime quando avvengono le transizioni attraverso una \emph{distribuzione di probabilità \keywordsub[distribuzione]{esponenziale}}
%     \item $\param{$\theta$}_{\setel{x}_{ij}}$, che esprime la \emph{distribuzione di probabilità \keywordsub[distribuzione]{multinomiale}} tra coppie di stati $i \neq j$.
% \end{itemize}
\begin{osservazione}
Si osservi che, aldilà del tipo di parametrizzazione con cui si sceglie di definire un modello di transizione, il numero di parametri necessari è pari a $K^2$ sebbene il numero di parametri liberi sia solo $K^2-K$~\citep{Nodelman2007}.
\end{osservazione}
\begin{osservazione}
Si noti, inoltre, che una parametrizzazione può essere più chiara dell'altra a seconda del processo in cui si è coinvolti, di conseguenza nel prosieguo le si utilizzerà entrambe in modo intercambiabile.
\end{osservazione}
Al fine di correlare questi due tipi di parametrizzazione dei modelli di transizione si riporta il seguente teorema~\citep{Nodelman2007}.
\begin{teorema}\label{th:rel-params}
Dati $\setel{X}$ e $\setel{Y}$, due \mprocess{} \omog{} con lo stesso spazio degli stati e la stessa distribuzione di probabilità iniziale, se il modello di transizione di $\setel{X}$ è definito tramite la \im*{} $\imsign{\setel{X}}$ e quello di $\setel{Y}$ è definito tramite la parametrizzazione \keywordsub[parametrizzazione]{mista} $\param{q}_{\setel{Y}}$, $\param{$\theta$}_{\setel{Y}}$, allora $\setel{X}$ e $\setel{Y}$ sono stocasticamente equivalenti\footnote{Due \mprocess{} sono detti \emph{stocasticamente equivalenti} se posseggono lo stesso spazio degli stati e le stesse probabilità di transizione~\citep{Gihman1973}.} solo se:
\[
\param{q}_{\setel{y}_i} = \param{q}_{\setel{x}_i}
\]
e
\[
\param{$\theta$}_{\setel{y}_i\setel{y}_j} = \frac{\param{q}_{\setel{x}_i\setel{x}_j}}{\param{q}_{\setel{x}_i}}\text{.}
\]
\end{teorema}
\begin{osservazione}
Si osservi che il \autoref{th:rel-params} formalizza la relazione che sussiste fra i parametri $\param{q}$ e $\param{$\theta$}$.
\end{osservazione}
Quindi, qualsiasi sia la parametrizzazione utilizzata per rappresentare il modello di transizione di un \mprocess*{} \omog*{} $\setel{X}$, è possibile calcolare:
\begin{itemize}
    \item il \emph{tempo atteso} di una transizione uscente dallo stato $\setel{x}_i$ \[1/\param{q}_{\setel{x}_i}\]
    \item la \emph{\virgolette{probabilità istantanea}} di transizione dallo stato $\setel{x}_i$ allo stato $\setel{x}_j$ sapendo che avverrà un salto ad un determinato istante di tempo \[\param{$\theta$}_{\setel{x}_i\setel{x}_j}=\param{q}_{\setel{x}_i\setel{x}_j}/\param{q}_{\setel{x}_i}\text{.}\]
\end{itemize}
Infine, si noti che la matrice $\imsign{\setel{X}}$ fa in modo che $\setel{X}$ soddisfi la proprietà di Markov poiché il comportamento futuro di $\setel{X}$ è definito solamente in base al suo stato attuale (vale l'\autoref{eq:homogeneus-markov-process}).

\begin{definizione}[\upcase\mprocess*{} \cond*{}]
\label{defn:conditional-markov-process}
Un \mprocess*{} le cui intensità di transizione variano nel tempo non in funzione del tempo ma in funzione dei valori assunti ad ogni determinato istante $t$ da un insieme di altre variabili, che evolvono anch'esse come dei processi di Markov, è detto essere un \mprocess*{} \cond*{} (o \mprocess*{} non \omog*{}).

Assumendo quindi che una variabile casuale $\setel{X}$ evolva come un \mprocess*{} $\setel{X}(t)$ e che la sua dinamica sia condizionata da un insieme di altre variabili casuali $Pa(\setel{X})$, anch'esse dei processi di Markov, è possibile definire per tale variabile casuale una \acf{CIM} $\cimsign{\setel{X}}{Pa(\setel{X})}$.

Specificando una distribuzione di probabilità iniziale su $\setel{X}$ si definisce quindi un \mprocess*{} il cui comportamento dipende dalle istanziazioni dei valori di $Pa(\setel{X})$.
\end{definizione}

\begin{definizione}[Matrice di intensità \cond*{}]
\label{defn:cim}
Dato un insieme di processi di Markov $Pa(\setel{X})$, una \im*{} \cond*{} $\cimsign{\setel{X}}{Pa(\setel{X})}$ è costituita da un insieme di \im{} $\cimsign{\setel{X}}{pa_i(\setel{x})}$, una per ogni diversa istanziazione $pa_i(\setel{x})$ di $Pa(\setel{X})$~\citep{Stella2012}:
\[
\cimsign{\setel{X}}{Pa(\setel{X})}=\big\{\,\cimsign{\setel{X}}{pa_1(\setel{x})}\,,\,\cimsign{\setel{X}}{pa_2(\setel{x})}\,,\,\dotsc\,,\,\cimsign{\setel{X}}{pa_n(\setel{x})}\,\big\}\text{.}
\]
Ogni matrice di intensità di $\cimsign{\setel{X}}{Pa(\setel{X})}$ è del seguente tipo:\\
\[
\cimsign{\setel{X}}{pa_i(\setel{x})}=
\begin{bmatrix}
-\param{q}_{\setel{x}_1}^{pa_i(\setel{x})}   & \param{q}_{\setel{x}_1\setel{x}_2}^{pa_i(\setel{x})} & \cdots & \param{q}_{\setel{x}_1\setel{x}_K}^{pa_i(\setel{x})}\\[0.5em]
\param{q}_{\setel{x}_2\setel{x}_1}^{pa_i(\setel{x})} & -\param{q}_{\setel{x}_2}^{pa_i(\setel{x})}   & \cdots & \param{q}_{\setel{x}_2\setel{x}_K}^{pa_i(\setel{x})}\\[0.5em]
\vdots           & \vdots           & \ddots & \vdots\\[0.5em]
\param{q}_{\setel{x}_K\setel{x}_1}^{pa_i(\setel{x})} & \param{q}_{\setel{x}_K\setel{x}_2}^{pa_i(\setel{x})} & \cdots & -\param{q}_{\setel{x}_K}^{pa_i(\setel{x})}
\end{bmatrix}
\text{.}
\]
\end{definizione}
Di seguito si presenta un breve esempio finalizzato alla comprensione pratica delle \cim{} (\acs{CIM}) e del loro scopo.
\begin{esempio}\label{ex:cim}\hfill\\
Date due variabili causali, $\setel{E}(t)$ e $\setel{H}(t)$, delle quali la prima modella l'eventualità che un individuo stia mangiando o meno (se $\setel{e}=2$ allora l'individuo sta mangiando, viceversa se $\setel{e}=1$) mentre la seconda modella l'eventualità che lo stesso individuo abbia fame o meno (se $\setel{h}=2$ allora l'individuo è affamato, viceversa se $\setel{h}=1$) e la \cim*{} $\cimsign{\setel{E}}{\setel{H}}$, che è un insieme composto dalle \im{} $\cimsign{\setel{E}}{h=1}$ e $\cimsign{\setel{E}}{h=2}$, è possibile calcolare la probabilità degli eventi della variabile casuale $\setel{E}$ condizionatamente all'evidenza che si possiede sulla variabile casuale $\setel{H}$.
\[
\cimsign{\setel{E}}{h=1}=\kbordermatrix{
\text{} &   1   &   2\cr
1       &  -.01 & .01\cr
2       & 10    & -10
}
\hspace*{25pt}
\cimsign{\setel{E}}{h=2}=\kbordermatrix{
\text{} &   1   &   2\cr
1       &  -2   &   2\cr
2       &   .01 & -.01
}\text{.}\\
\]
Ipotizzando che l'unità temporale corrisponda a un'ora:
\begin{itemize}
    \item un individuo affamato ($\setel{h}=2$) che non sta mangiando ($\setel{e}=1$) inizierà a mangiare in 30 minuti poiché \[\frac{1}{\param{q}_{\setel{e}=1\,\arrowvert\,\setel{h}=2}}=\frac{1}{2}\:\text{,}\]
    \item un individuo non affamato ($\setel{h}=1$) che sta mangiando ($\setel{e}=2$) smetterà di mangiare ($\setel{e}=1$) entro 6 minuti poiché \[\frac{1}{\param{q}_{\setel{e}=2\,\arrowvert\,\setel{h}=1}}=\frac{1}{10}\:\text{;}\] si osservi che la\emph{\virgolette{probabilità istantanea}} di transizione da $\setel{e}=2$ a $\setel{e}=1$ è \[\param{$\theta$}_{\setel{e}=2,\setel{e}=1\,\arrowvert\,\setel{h}=1}=\frac{\param{q}_{\setel{e}=2,\setel{e}=1\,\arrowvert\,\setel{h}=1}}{\param{q}_{\setel{e}=2\,\arrowvert\,\setel{h}=1}}=\frac{10}{10}=1\text{,}\]
    ciò poiché le \im{} hanno dimensione $2 \times 2$ e, dovendo ogni loro riga sommare a $0$, gli elementi sulla diagonale sono uguali al rispettivo (stessa riga) e unico elemento non sulla diagonale.
\end{itemize}
\end{esempio}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Definizioni preliminari}
\label{sec:Definizioni preliminari}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Nelle precedenti sezioni sono stati illustrati i concetti che si pongono a fondamento delle \acl{CTBN}:
\begin{itemize}
    \item le \acl{BN}: utili a comprendere la rappresentazione strutturata dello spazio degli stati delle \acs{CTBN}, l'utilizzo della nozione di indipendenza \cond*{} e le conseguenti tecniche di apprendimento e inferenza
    \item i \mprocess{}, \omog{} e non, al fine di introdurre le modalità di rappresentazione (qualitativa e quantitativa) delle \acs{CTBN}.
\end{itemize}

Prima di presentare le \acl{CTBN} come una collezione di \ctmp{} non \omog{} e con spazio degli stati discreto~\citep{Nodelman2007}, si forniscono alcune definizioni utili per il prosieguo della discussione.

\begin{definizione}[\acl{PV}]\label{defn:pv}
    Una \pv{} $\set{X}$, anche detta \ACF{PV}~\citep{Nodelman2007}, è un insieme di \ctmp{} $\setel{X}(t)$.
\end{definizione}

\begin{definizione}[Traiettoria]\label{defn:traiettoria}
    Istanziazione di un insieme di valori per $\setel{X}(t)$ al variare di $t$.
\end{definizione}

\begin{definizione}[$J$-time-segment]\label{defn:j-time-segment}
Partizionamento di un intervallo temporale $[\,0,\,T)$ in $J$ intervalli chiusi a sinistra:
\[
[\,0,\,t_1)\:;\:[\,t_1,\,t_2)\:;\:\dotsc\:;\:[\,t_{J-1},\,T)\text{.}
\]
\end{definizione}
\begin{notabene}
\`E possibile riferirsi a tale concetto anche tramite l'espressione \emph{\virgolette{insieme dei \keywordsub[definizione]{segmenti temporali}}}.
\end{notabene}
\begin{definizione}[$J$-evidence-stream]\label{defn:j-evidence-stream}
Data una \pv{} $\set{X}$ composta da $N$ variabili casuali e un insieme di segmenti temporali composto da $J$ intervalli, un \emph{$J$-evidence-stream} è l'insieme delle istanziazioni comuni $\set{X}=\set{x}$ associate ad ogni intervallo temporale per ogni sottoinsieme delle variabili casuali~\citep{Stella2012}. \`E denotato con $(\set{X}^1=\set{x}^1\,,\,\set{X}^2=\set{x}^2\,,\,\dotsc\,,\,\set{X}^J=\set{x}^J)$, o più concisamente con $\evidencestream{J}$.
\end{definizione}
\begin{notabene}
\`E possibile riferirsi a tale concetto anche tramite l'espressione \emph{\virgolette{flusso di evidenze}}.
\end{notabene}
\begin{notabene}
Un flusso di evidenze $\evidencestream{J}$. è detto essere \emph{completamente osservato} se lo stato di tutte le variabili $\setel{X_n}\in\set{X}$ è conosciuto in tutto l'intervallo $[\,0,\,T)$. Viceversa, un flusso di evidenze è detto \emph{parzialmente osservato}.
\end{notabene}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Rappresentazione}
\label{sec:ctbn-rappresentazione}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Una \acl{CTBN} è un modello grafico in cui ogni nodo rappresenta una variabile casuale i cui stati evolvono in modo continuo bel tempo. Le dinamiche evolutive degli stati dei nodi sono governate e dipendono dal valore che gli stati dei nodi padre\footnote{Con il termine \virgolette{nodo padre}, o \emph{parent node}, si intende un nodo il cui stato condiziona quello di un altro nodo del modello grafico.} assumono~\citep{Nodelman2007}. Quindi ogni nodo è un \mprocess*{} \cond*{} (si veda la \autoref{defn:conditional-markov-process}) a tempo continuo e spazio degli stati discreto.

Una \acs{CTBN} è composta principalmente da due componenti:
\begin{itemize}
    \item una distribuzione di probabilità iniziale
    \item le componenti che regolano l'evoluzione nel tempo del sistema
\end{itemize}
Più formalmente si definisce:
\begin{definizione}[\acl{CTBN}]
\label{defn:ctbn}
Data una \pv{} $\set{X}$, insieme di processi di Markov $\setel{X_1}\,,\,\setel{X_2}\,,\,\dotsc\,,\,\setel{X_N}$ a tempo continuo e con spazio degli stati finito $val(\setel{X_n})=\{\,\vectel{\setel{x}_1}\,,\,\dotsc\,,\,\vectel{\setel{x}_J}\,\}$ (dove $n=1\,,\,\dotsc\,,\,N$), una \acs{CTBN} $\conceptsym{N}$ su $\set{X}$ consiste di:
\begin{itemize}
    \item una distribuzione di probabilità iniziale $\priorsign{\set{X}}$ specificata come una \bn{} $\conceptsym{B}$ su $\set{X}$
    \item un modello di transizione a tempo continuo, specificato da:
    \begin{itemize}
        \item un grafo $\conceptsym{G}$, orientato e non necessariamente aciclico, composto dai nodi $\setel{X_1}\,,\,\setel{X_2}\,,\,\dotsc\,,\,\setel{X_N}$, ognuno dei quali possiede un insieme di genitori denotato da $Pa(\setel{X_n})$
        \item una \im*{} \cond*{} $\cimsign{\setel{X_n}}{Pa(\setel{X_n})}$ per ogni nodo $\setel{X_n} \in \set{X}$.
    \end{itemize}
\end{itemize}
\end{definizione}

Per ogni variabile causale $\setel{X_n} \in \set{X}$ di $\conceptsym{N}$ si ha quindi un insieme di modelli di probabilità locali: $\cimsign{\setel{X_n}}{Pa(\setel{X_n})}$, la \acs{CIM} di $\setel{X_n}$, è infatti un insieme di modelli di transizione Markoviani la cui cardinalità è pari a quella dell'insieme delle diverse istanziazioni di $Pa(\setel{X_n})$.

Si riscontra, quindi, quanto già affermato in precedenza (si veda la \vref{sec:fondamenti-mp}), cioè che una \acs{CTBN} esprime la sua dinamica evolutiva globale tramite un unico \mprocess*{} \omog*{}, costituito da un insieme di \mprocess{} \cond{} (un insieme di \acs{CIM} e relative distribuzioni di probabilità iniziali).

Si noti che, diversamente dalle \acl{BN}, nelle \acl{CTBN} gli archi fra i nodi rappresentano le dipendenze nel tempo. Per tale motivo è possibile che la componente $\conceptsym{G}$ del modello di transizione continuo contenga dei cicli. Tra l'altro, come vedremo nel prosieguo, la mancanza di tale vincolo di aciclicità porta a notevoli vantaggi computazionali relativamente all'apprendimento della struttura di una \acs{CTBN} dai dati.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Apprendimento}
\label{sec:ctbn-apprendimento}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In questa sezione si argomenta sulla probabilità di un \emph{insieme di dati completo} rispetto a una \acl{CTBN}. A tal fine si mostra come una \acs{CTBN} possa essere decomposta in un aggregato di modelli di probabilità locali relativi alle singole variabili casuali e espressa in termini di \emph{\stats{}} aggregate.

Si affronta infine il processo di apprendimento dei parametri delle \acl{CTBN} da \emph{dati completi}. I processi di apprendimento relativi a dati non completi sono tralasciati poiché non facenti parte degli argomenti di questo lavoro di tesi.

\begin{definizione}[Insieme di dati completo]
\label{defn:dataset-completo}
Dato un insieme di variabili casuali, un insieme di dati $\conceptsym{D}=\{\,\delta_1\,,\,\dotsc\,,\,\delta_h\,\}$ si dice \emph{completo} se ogni $\delta_i$ (con $i=1\,,\,\dotsc\,,\,h$) è un insieme di traiettorie completamente osservate delle variabili casuali (\ie{} l'istanziazione di tutte le variabili casuali è osservabile per ogni istante temporale di ogni traiettoria).
\end{definizione}

\subsection{Statistiche sufficienti}
\label{subsec:ctbn-sufficient-stats}
Le \emph{\stats{}} per un singolo \mprocess*{} \omog*{} $\setel{X}(t)$ riassumono la sua dinamica evolutiva con:
\begin{itemize}
    \item $\tstat{x}$: la quantità di tempo trascorsa nello stato $\setel{x}$
    \item $\mstat[x]{\setel{x}^\prime}$: il numero di transizioni dallo stato $\setel{x}$ allo stato $\setel{x}^\prime$.
\end{itemize}

Il numero totale di transizioni uscenti da uno stato $\setel{x}$ è:
\[
\mstat{x}=\sum_{\setel{x}^\prime}\mstat[x]{\setel{x}^\prime}\text{.}
\]
Nel caso di un \mprocess*{} \cond*{} è invece necessario considerare anche l'istanziazione dell'insieme $Pa(\setel{X})$ dei nodi genitori:
\begin{itemize}
    \item $\tstat{x\,\arrowvert\,pa_i(\setel{x})}$: la quantità di tempo trascorsa nello stato $\setel{x}$ quando $Pa(\setel{X})=pa_i(\setel{x})$
    \item $\mstat[x]{\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}$: il numero di transizioni dallo stato $\setel{x}$ allo stato $\setel{x}^\prime$ quando $Pa(\setel{X})=pa_i(\setel{x})$.
\end{itemize}
Chiaramente, il numero totale di transizioni si calcola come sopra.

\subsection{Likelihood}
\label{subsec:ctbn-likelihood}
Al fine di presentare il calcolo della likelihood\footnote{\label{note:likelihood}La likelihood di un insieme di valori dei parametri, dato un insieme di dati, corrisponde alla probabilità dell'insieme dei dati, dati tali valori dei parametri.} di una \acs{CTBN} rispetto a un dataset completo $\conceptsym{D}=\{\,\delta_1\,,\,\dotsc\,,\,\delta_h\,\}$ è bene procedere per gradi e iniziare presentando dapprima la likelihood di una singola transizione di un singolo \mprocess*{} \omog*{} $\setel{X}(t)$.

\subsubsection{Likelihood di una singola transizione}
\label{subsec:ctbn-likelihood-single-trans-single-hmp}
Data una tripla $d=\langle \,\setel{x}_{d}\,,\,t_d\,,\,\setel{x}_{d^{\prime}}\,\rangle\in\delta$, la quale esprime una transizione di $\setel{X}(t)$ da $\setel{x}_d$ a $\setel{x}_{d^{\prime}}$ dopo che esso ha trascorso $t_d$ tempo in $\setel{x}_d$, è possibile scrivere la likelihood di questa singola transizione $d$ in funzione dei parametri:
\begin{equation}
\label{eq:ctbn-trans-hmm-likelihood}
\begin{split}
L_{\setel{X}}(\param{q}\,,\,\param{$\theta$}:d) &= L_{\setel{X}}(\param{q}:d) \cdot L_{\setel{X}}(\param{$\theta$}:d) \\
&= \param{q}_{\setel{x}_d}\,e^{-\param{q}_{\setel{x}_d}t_d} \cdot \param{$\theta$}_{\setel{x}_{d}\setel{x}_{d^{\prime}}}\text{.}
% &= \param{q}_{\setel{x}_d}\,\exp(-\param{q}_{\setel{x}_d}\,t_d)\,\Big(\frac{\param{q}_{\setel{x}_{d}\setel{x}_{d^{\prime}}}}{\param{q}_{\setel{x}_d}}\Big) \\
% &= \exp(-\param{q}_{\setel{x}_d}\,t_d)\,\param{q}_{\setel{x}_{d}\setel{x}_{d^{\prime}}}
\end{split}
\end{equation}
Si noti che l'\autoref{eq:ctbn-trans-hmm-likelihood} è ricavata moltiplicando la \emph{funzione di distribuzione di probabilità} di $\setel{X}(t)$ (\autoref{eq:im-distrib}) per la \emph{\virgolette{probabilità istantanea}} di transizione (si veda la \autoref{defn:im}).

\subsubsection{Likelihood di un dataset completo}
\label{subsec:ctbn-likelihood-dataset}
Poiché tutte le transizioni sono osservabili, la \emph{likelihood} del dataset $\conceptsym{D}$ può essere decomposta come un prodotto delle likelihood individuali di ogni singola transizione $d$~\citep[si veda][3]{Nodelman2002}. Per tale motivo $\conceptsym{D}$ è sintentizzabile aggregando le \emph{\stats{}} relative a ogni \mprocess*{} \cond*{} di una \acs{CTBN}.

Quindi la likelihood di un dataset completo $\conceptsym{D}$ rispetto a un singolo \mprocess*{} \omog*{} $\setel{X}(t)$ è:
\begin{equation}
\label{eq:ctbn-data-hmp-likelihood}
\begin{split}
L_{\setel{X}}(\param{q}\,,\,\param{$\theta$}:\conceptsym{D})&=\bigg[\prod_{d\in\conceptsym{D}}L_{\setel{X}}(\param{q}:d)\bigg]\bigg[\prod_{d\in\conceptsym{D}}L_{\setel{X}}(\param{$\theta$}:d)\bigg]\\[5pt]
&=\Big[\prod_{\setel{x}}(\param{q}_{\setel{x}})^{\mstat{x}}e^{-\param{q}_{\setel{x}}\tstat{x}}\Big]\Big[\prod_{x}\prod_{x\neq x^{\prime}}(\param{$\theta$}_{\setel{x}\setel{x}^{\prime}})^{\mstat[x]{\setel{x}^\prime}}\Big]\text{.}
\end{split}
\end{equation}
Si supponga ora di traslare questo concetto a una \acl{CTBN} $\conceptsym{N}$ con $N$ nodi: per ogni nodo $\setel{X_i}$, con $i=1\,,\,\dotsc\,N$ è necessario considerare tutte le transizioni contestualmente all'istanziazione dell'insieme $Pa(\setel{X_i})$ dei suoi nodi genitori. Poiché, nel caso di \emph{dati completi}, si conosce sempre l'istanziazione di $Pa(\setel{X_i})$, allora, per ogni istante di tempo $t$, si conosce quale \im*{} $\cimsign{\setel{X_i}}{pa_i(\setel{x})}\,$, con $pa_i(\setel{x})\in Pa(\setel{X_i})\,$, governi la dinamica di $\setel{X_i}$.

Perciò la probabilità dei dati $\conceptsym{D}$ rispetto a $\conceptsym{N}$ è il prodotto delle likelihood di ogni variabile $\setel{X_i}$:
\begin{align}\label{eq:ctbn-likelihood-decomp}
L_{\conceptsym{N}}(\param{q}\,,\,\param{$\theta$}\,:\conceptsym{D})&=\prod_{\setel{X}_i\in\,\set{X}}L_{\setel{X}_i}(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}\,,\,\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D}) \nonumber\\
&=\prod_{\setel{X}_i\in\,\set{X}} L_{\setel{X}_i}(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D}) \, L_{\setel{X}_i}(\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D})\text{.}
\end{align}
Il termine $L_{\setel{X}}(\param{$\theta$}_{\,\setel{X}\,\arrowvert\,Pa(\setel{X})}:\conceptsym{D})$ esprime la likelihood delle transizioni tra stati. Tale termine trascura il tempo che intercorre fra le transizioni poiché esse dipendonono esclusivamente dal valore di nodi genitori~\citep[si veda][3]{Nodelman2002}. Quindi, usando le \emph{\stats{}} si può scrivere:
\begin{equation}\label{eq:like-transitions}
L_{\setel{X}}(\param{$\theta$}_{\,\setel{X}\,\arrowvert\,Pa(\setel{X})}:\conceptsym{D})=\prod_{pa_i(\setel{x})} \prod_{x} \prod_{x\neq x^{\prime}}(\param{$\theta$}_{xx^{\prime}\,\arrowvert\,pa_i(\setel{x})})^{\mstat[x]{\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}}\text{.}
\end{equation}
Per quanto riguarda il calcolo di $L_{\setel{X}}(\param{q}_{\,\setel{X}\,\arrowvert\,Pa(\setel{X})}:\conceptsym{D})$ va considerato il caso in cui il tempo trascorso da $\setel{X}$ in uno determinato stato $\setel{x}$ termini non a causa di una sua transizione bensì a causa di una transizione di uno o più nodi appartenenti all'insieme dei suoi nodi genitori (\ie{} una nuova istanziazione per l'insieme dei genitori $Pa(\setel{X})$). \`E quindi necessario considerare la probabilità che il nodo $\setel{X}$ rimanga in $\setel{x}$ una quantità di tempo \emph{almeno pari} a $t$ mentre i suoi nodi genitori $Pa(\setel{X})$ non effettuano alcuna transizione di stato~\citep[si veda][3]{Nodelman2002}. Tale quantità si ricava dalla funzione di distribuzione cumulativa di una distribuzione \keywordsub[distribuzione]{esponenziale} (\autoref{eq:im-distrib}):
\[
1-F(t)=e^{-\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}t}\text{.}
\]
Perciò la likelihood delle quantità di tempo trascorse in ogni stato è:
\footnotesize
\begin{equation}\label{eq:like-time-spent-in-each-state}
L_{\setel{X}}(\param{q}_{\,\setel{X}\,\arrowvert\,Pa(\setel{X})}:\conceptsym{D})=\prod_{pa_i(\setel{x})}\prod_{x}(\param{q}_{x\,\arrowvert\,pa_i(\setel{x})})^{\mstat{x\,\arrowvert\,pa_i(\setel{x})}}e^{-\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}\,\tstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})}}\text{\normalsize .}\vspace{1mm}
\end{equation}\normalsize
Combinando l'\autoref{eq:like-time-spent-in-each-state} e l'\autoref{eq:like-transitions} si ottiene la likelihood di un dataset completo $\conceptsym{D}$ rispetto a un singolo \mprocess*{} \cond*{}:
\footnotesize
\begin{align}\label{eq:ctbn-var-likelihood}
L_{\setel{X}}(\param{q}\,,\,\param{$\theta$}\,:\conceptsym{D}) &= \prod_{pa_i(\setel{x})}\prod_{\setel{x}} \bigg[ (\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})})^{\mstat{x\,\arrowvert\,pa_i(\setel{x})}}e^{-\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}\,\tstat{x\,\arrowvert\,pa_i(\setel{x})}} \cdot \bigg.\nonumber\\
& \qquad \bigg.{} \qquad \qquad \cdot \prod_{\setel{x}\neq \setel{x}^{\prime}}(\param{$\theta$}_{\setel{x}\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})})^{\mstat[x]{\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}} \bigg] \text{\normalsize .}
\end{align}
\normalsize
Si noti che, dal punto di vista algebrico, è conveniente riformulare l'\autoref{eq:ctbn-var-likelihood} come \emph{log-likelihood}:
\footnotesize
\begin{align}\label{eq:ctbn-var-log-likelihood}
\ell_{\setel{X}}(\param{q}\,,\,\param{$\theta$}\,:\conceptsym{D}) &= \sum_{pa_i(\setel{x})}\sum_{\setel{x}} \bigg[ \mstat{x\,\arrowvert\,pa_i(\setel{x})}\ln(\param{q}_{x\,\arrowvert\,pa_i(\setel{x})})- \param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}\tstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})} + \bigg.\nonumber\\
& \qquad \bigg.{} \qquad \qquad + \sum_{\setel{x}\neq \setel{x}^{\prime}}\mstat[x]{\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}\ln(\param{$\theta$}_{\setel{x}\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}) \bigg] \text{\normalsize .}
\end{align}
\normalsize
\`E ora possibile asserire che la \emph{log-likelihood} di $\conceptsym{N}$ (dall'\autoref{eq:ctbn-likelihood-decomp}) è:
\begin{equation}\label{eq:ctbn-log-likelihood}
\ell_{\conceptsym{N}}(\param{q}\,,\,\param{$\theta$}\,:\conceptsym{D})=\sum_{\setel{X}_i \in \, \set{X}} \ell_{\setel{X}_i}(\param{q}\,,\,\param{$\theta$}\,:\conceptsym{D}) \text{.}
\end{equation}

In questa sezione si è presentato come computare la likelihood di un modello di una \acs{CTBN} rispetto a un dataset completo.

Tuttavia, nel caso in cui non si conoscano i parametri di una \acs{CTBN} è necessario stimarli. Nella prossima sezione viene affrontato esattamente questo argomento.

\subsection{Stima dei parametri}\label{subsec:ctbn-params}
Si affronta ora il problema dell'\keywordsub[parametrizzazione]{apprendimento} dei parametri di una \acl{CTBN} (con struttura nota $\conceptsym{G}$) da un insieme di dati completi~\citep[si veda][sezione 5.1]{Nodelman2007}.

Quando si tratta con \keywordsub[apprendimento]{dati multinomiali} ci sono principalmente due scelte che è possibile fare. La scelta più semplice consiste nell'effettuare una stima dei parametri del modello tramite un approccio \emph{\acl{MLE}}. Tuttavia, è noto che tale approccio può portare a problemi con l'inferenza quando i dati di input sono sparsi. Per evitare tale limitazione solitamente si effettua una \emph{\keywordsub[apprendimento]{regolarizzazione} bayesiana} dei parametri: si sceglie una distribuzione a priori per i parametri e li si aggiorna in accordo ai dati di input.

La \keywordsub[parametrizzazione]{stima} dei parametri non è un processo fine a se stesso, in quanto, \graffito{Come costruire una \acs{CIM} dai parametri.} da essi è possibile costruire le \cim{} (\acs{CIM}) di ogni nodo della \acs{CTBN}. Come si ricorderà, una \acs{CIM} è un insieme di \im{}, una per ogni istanziazione $pa_i(\setel{x})$ dei nodi genitori (si veda la \autoref{defn:cim}). Perciò, fissato $pa_i(\setel{x})$, si può computare la rispettiva \im*{} per un nodo qualsiasi ponendo sulla diagonale il rispettivo vettore dei parametri $\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$ e ricavando i valori non sulla diagonale dalla relazione (si veda il \autoref{th:rel-params}) fra i parametri $\param{q}$ e $\param{$\theta$}$:
\begin{equation}
\label{eq:ctbn-params-rel}
\param{q}_{\setel{x}\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}=\param{$\theta$}_{\setel{x}\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})} \cdot \param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}\text{.}
\end{equation}
Infine, come vedremo in seguito nel \autoref{cap:structurallearning}, i parametri sono anche un componente chiave del processo di apprendimento strutturale.

\subsubsection{Stima \acl{MLE}}
\label{subsec:ctbn-mle-params}
In base a quanto attestato dalla definizione stessa delle \acs{CTBN} (\vref{defn:ctbn}), la dinamica evolutiva globale di una \acs{CTBN}, cioè la dinamica di tutti i nodi di $\conceptsym{G}$ (dei \mprocess{} \cond{} indicizzati dal tempo), è espressa tramite un \mprocess*{} \omog*{}. Dalla \autoref{defn:im}, inoltre, si deduce che tale \mprocess*{} induce un modello di probabilità composto da una \emph{distribuzione \keywordsub[distribuzione]{esponenziale}} con parametro $\param{q}_{x\,\arrowvert\,pa_i(\setel{x})}$, che esprime il tempo trascorso in uno stato $\setel{x}$ da un nodo $\setel{X}$ data una istanziazione $pa_i(\setel{x})$ per i nodi genitori $Pa(\setel{X})$, e una \emph{distribuzione \keywordsub[distribuzione]{multinomiale}} con parametro $\param{$\theta$}_{\setel{x}\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}$, che esprime la probabilità di transizione uscenti dallo stato $\setel{x}$ verso $\setel{x}^\prime$ (sempre fermo restando il condizionamento dato dall'istanziazione dei nodi genitori).

La media della distribuzione \keywordsub[distribuzione]{esponenziale} in questione è pari a $1/\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$. Questa quantità esprime il tempo medio delle transizioni uscenti da uno stato $\setel{x}$, fermo restando che il genitore del nodo in questione abbia istanziazione costante e uguale a $pa_i(\setel{x})$. Poiché il tempo medio si calcola rapportando il tempo totale trascorso in $\setel{x}$, $\tstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$, rispetto al numero totale di transizioni uscenti da $\setel{x}$, $\mstat{x\,\arrowvert\,pa_i(\setel{x})}$, si ottiene:
\[
\frac{1}{\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}}=\frac{\tstat{x\,\arrowvert\,pa_i(\setel{x})}}{\mstat{x\,\arrowvert\,pa_i(\setel{x})}}\text{.}
\]

Invece, la probabilità di transizione da uno stato $\setel{x}$ verso $\setel{x}^\prime$ sapendo che avverrà una transizione è data dal rapporto tra il numero totale di transizioni da $\setel{x}$ a $\setel{x}^\prime$ diviso il numero totale di transizioni uscenti da $\setel{x}$; cioè:
\[
\frac{\mstat[x]{\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}}{\mstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})}}\text{.}
\]

\begin{teorema}{Parametri \ac{MLE}.}
I parametri che massimizzano la likelihood (\autoref{eq:ctbn-log-likelihood}) di una \acl{CTBN} sono funzione delle \stats{}:
\begin{equation}
\label{eq:ctbn-params}\normalfont
\begin{split}
\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}&=\frac{\mstat{x\,\arrowvert\,pa_i(\setel{x})}}{\tstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})}} \\
\param{$\theta$}_{\setel{x}\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}&=\frac{\mstat[x]{\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}}{\mstat{\setel{x}\,\arrowvert\,pa_i(\setel{x})}}\text{.}
\end{split}
\end{equation}
\end{teorema}
\normalfont
Si noti che, in questo caso (\emph{dataset completo}), $\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$ e $\param{$\theta$}_{\setel{x}\setel{x}^\prime\,\arrowvert\,pa_i(\setel{x})}$ sono delle \emph{\keywordsub[apprendimento]{stime esatte}}. Essi massimizzano la probabilità a posteriori di un dataset, dato un modello \acs{CTBN}.

\subsubsection{Stima bayesiana}
\label{subsec:ctbn-bayesian-estimate}
Un approccio alternativo alla \keywordsub[apprendimento]{stima dei parametri} è la \keywordsub[apprendimento]{stima bayesiana}~\citep[si veda][sottosezione 5.1.1]{Nodelman2007}.

A tal fine è necessario definire una distribuzione a priori sui parametri di una \acs{CTBN}. Come si è soliti fare in situazioni di questo tipo, per tale distribuzione si sceglie di usare una \emph{distribuzione a \keywordsub[apprendimento]{priori coniugata}}\footnote{\label{note:conjugate-prior}In teoria della probabilità bayesiana, se le distribuzioni a posteriori $P(\param{$\theta$}|\setel{x})$ sono nella stessa famiglia della distribuzione a priori $P(\param{$\theta$})$, le due distribuzioni sono definite coniugate, e la distribuzione a priori è chiamata \emph{distribuzione a \keywordsub[definizione]{priori coniugata}} per la verosimiglianza (\emph{likelihood}). Una distribuzione a priori coniugata è conveniente dal punto di vista algebrico in quanto fornisce una espressione in forma chiusa per la distribuzione a posteriori e perché può fornire delle intuizioni circa il modo con cui la funzione di verosimiglianza aggiorna la distribuzione.} poiché ciò risulta conveniente dal punto di vista algebrico (e quindi computazionale). Infatti, una distribuzione a priori coniugata fornisce un'espressione in forma chiusa per la distribuzione a posteriori (alternativamente potrebbe risultare necessario il calcolo di un integrale numerico).

Si consideri innanzitutto un singolo \mprocess*{}. Si ricorda (si vedano a tal riguardo le~\cref{defn:im,defn:mixed-parametrization}~\vpageref{defn:im,defn:mixed-parametrization}) che un \mprocess*{} ha due insiemi di parametri: $\param{$\theta$}$ che parametrizzano una \emph{distribuzione \keywordsub[distribuzione]{multinomiale}} e $\param{q}$ che parametrizzano una \emph{distribuzione \keywordsub[distribuzione]{esponenziale}}.

Una distribuzione a \keywordsub[apprendimento]{priori coniugata} per il parametro $\param{q}$ è la \emph{distribuzione \keywordsub[distribuzione]{Gamma}} $P(\param{q})=Gamma(\alpha_{\setel{x}},\,\tau_{\setel{x}})$, dove~\citep[si veda][]{Nodelman2007}:
\begin{equation}\label{eq:ctbn-bayesian-params-gamma}
P(\param{q})=\frac{ \tau_{\setel{x}}^{\,\alpha_{\setel{x}+1}} }{ \Gamma(\alpha_{\setel{x}+1}) } \param{q}^{ \alpha_{\setel{x}} } \, e^{ -\param{q}\tau_{\setel{x}} } \text{.}
\end{equation}
Invece, avendo assunto l'indipendenza dei parametri e poiché la funzione di densità della distribuzione di probabilità di $\param{$\theta$}$, che è una \keywordsub[distribuzione]{multinomiale}, è positiva, per essa si sceglie come \keywordsub[apprendimento]{priori coniugata} la \emph{distribuzione di \keywordsub[distribuzione]{Dirichlet}} $P(\param{$\theta$})=Dir(\alpha_{\setel{x}\setel{x}_1},\,\dotsc\,,\alpha_{\setel{x}\setel{x}_K})$~\citep[si veda][]{Heckerman1996,Heckerman1995}, la cui funzione di densità~\citep{Steck2002} è:
\begin{equation}\label{eq:ctbn-bayesian-params-dirichlet}
P(\param{$\theta$})=\frac{ \Gamma(\alpha_{\setel{x}}) }{ \Gamma(\alpha_{\setel{x}\setel{x}_1}) \cdot \,\dotsc\, \cdot \Gamma(\alpha_{\setel{x}\setel{x}_K}) } \param{$\theta$}_{\setel{x}\setel{x}_k}^{\alpha_{\setel{x}\setel{x}_1}-1} \cdot \,\dotsc\, \cdot \param{$\theta$}_{\setel{x}\setel{x}_1}^{\alpha_{\setel{x}\setel{x}_K}-1} \text{.}
\end{equation}
\begin{nota}
Si noti che l'iper-parametro $\alpha_{\setel{x}}$, detto \emph{dimensione equivalente del campione}, è costituito dalla somma dei \emph{\keywordsub[apprendimento]{conteggi immaginari}} $\alpha_{\setel{x}\setel{x}_1} + \, \dotsc \, + \alpha_{\setel{x}\setel{x}_K}$, chiamati anche \emph{\keywordsub[apprendimento]{pseudo-conteggi}}~\citep{Steck2002}. Esso può essere pensato come un fattore che esprime la \emph{\virgolette{forza}} della distribuzione a priori, in quanto, più esso aumenta, più le stime dei parametri sono regolarizzate, cioè meno estreme. Chiaramente, quando $\alpha_{\setel{x}}$ tende a $0$ le stime dei parametri tendono alle stime \acl{MLE}. In letteratura~\citep[si veda][]{Steck2002} questo processo è anche chiamato \emph{\virgolette{\keywordsub[apprendimento]{smoothing}}}.
\end{nota}
\begin{nota}
L'iper-parametro $\tau_{\setel{x}}$, invece, rappresenta una \emph{quantità di tempo immaginaria} che incorpora la credenza della distribuzione a priori sul parametro della distribuzione esponenziale.
\end{nota}
Quindi, se si assume che i parametri sono \emph{stocasticamente indipendenti}, cioè che $P(\param{$\theta$},\param{q})=P(\param{$\theta$})\,P(\param{q})$, allora le distribuzioni a posteriori (\ie{} condizionate sui dati) dei parametri $\param{q}$ e $\param{$\theta$}$ sono:
\begin{equation}\label{eq:ctbn-bayesian-params-posteriors}
\begin{aligned}
P(\param{q}\,\arrowvert\,\conceptsym{D})&=Gamma(\alpha_{\setel{x}}+\mstat{x},\,\tau_{\setel{x}}+\tstat{x}) \\
P(\param{$\theta$}\,\arrowvert\,\conceptsym{D})&=Dir(\alpha_{\setel{x}\setel{x}_1}+\mstat[x]{\setel{x}_1},\,\dotsc\,,\alpha_{\setel{x}\setel{x}_K}+\mstat[x]{\setel{x}_K})\text{.}
\end{aligned}
\end{equation}

Al fine di generalizzare quest'idea e ottenere una distribuzione a \keywordsub[apprendimento]{priori coniugata} per un'intera \acs{CTBN} è necessario che essa soddisfi due assunzioni (comuni per le distribuzioni a priori nelle \acl{BN}, si veda~\citet{Heckerman1996}): l'\keywordsub[apprendimento]{indipendenza globale} e \keywordsub[apprendimento]{locale} dei parametri. In base all'\emph{\keywordsub[apprendimento]{indipendenza globale} dei parametri} si può scrivere:
\begin{equation}\label{eq:ctbn-bayesian-params-globalind}
P(\param{q}\,,\param{$\theta$})=\prod_{\setel{X}_i\in\set{X}}\,P(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}\,,\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)})\text{.}
\end{equation}
Invece, dall'\emph{\keywordsub[apprendimento]{indipendenza locale} dei parametri} consegue che è possibile scrivere:
\footnotesize
\begin{equation}\label{eq:ctbn-bayesian-params-localind}
P(\param{q}_{\setel{X}\,\arrowvert\,Pa(\setel{X})}\,,\,\param{$\theta$}_{\setel{X}\,\arrowvert\,Pa(\setel{X})}) = \bigg[ \prod_{\setel{x}}\prod_{pa_i(\setel{x})} P(\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}) \bigg] \bigg[ \prod_{\setel{x}}\prod_{pa_i(\setel{x})} P(\param{$\theta$}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}) \bigg]\text{\normalsize .}
\end{equation}\normalsize
Se tale distribuzione a priori soddisfa le assunzioni di indipendenza allora anche la distribuzione a posteriori, essendovi coniugata e perciò appartenente alla stessa famiglia parametrica, le soddisferà. In tal caso è possibile mantenere la distribuzione parametrica in forma chiusa e aggiornarla usando le \emph{\keywordsub[apprendimento]{stats{}}}:
\begin{itemize}
\item $\mstat[x]{\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}$ per il parametro $\param{$\theta$}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$
\item $\mstat{x\,\arrowvert\,pa_i(\setel{x})}$ e $\tstat{x\,\arrowvert\,pa_i(\setel{x})}$ per il parametro $\param{q}_{\setel{x}\,\arrowvert\,pa_i(\setel{x})}$.
\end{itemize}
Data una distribuzione sui parametri è possibile usarla per predire il prossimo evento, mediando la sua probabilità sull'insieme dei possibili valori dei parametri. Questo tipo di previsione è equivalente all'utilizzo dei \emph{\keywordsub[apprendimento]{valori attesi}} dei parametri, i quali hanno la stessa forma dei parametri \acl{MLE} ma considerano i \emph{\keywordsub[apprendimento]{conteggi immaginari}} degli iper-parametri:
\begin{equation}
\label{eq:ctbn-imaginary-params}
\begin{split}
\paramhat{q}_{x\,\arrowvert\,pa_i(\setel{x})}&=\frac{\alpha_{\setel{x}\,\arrowvert\,pa_i(\setel{x})} + \mstat{x\,\arrowvert\,pa_i(\setel{x})}}{\tau_{\setel{x}\,\arrowvert\,pa_i(\setel{x})} + \tstat{x\,\arrowvert\,pa_i(\setel{x})}} \\
\greekhat{\theta}_{xx^\prime\,\arrowvert\,pa_i(\setel{x})}&=\frac{\alpha_{\setel{x}\setel{x}^{\prime}\,\arrowvert\,pa_i(\setel{x})}+\mstat[x]{x^\prime\,\arrowvert\,pa_i(\setel{x})}}{\alpha_{\setel{x}\,\arrowvert\,pa_i(\setel{x})} + \mstat{x\,\arrowvert\,pa_i(\setel{x})}}\text{.}
\end{split}
\end{equation}
Si osservi che questi parametri sono, teoricamente, validi solo per predire una singola transizione, dopo la quale la distribuzione dei parametri andrebbe aggiornata di conseguenza. Tuttavia, è prassi comune non aggiornare la distribuzione dei parametri utilizzando i succitati \emph{\keywordsub[apprendimento]{valori attesi}} anche per la previsione delle transizioni successive.
