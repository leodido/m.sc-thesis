% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../arsclassica.tex
% !TEX spellcheck = it-IT

%************************************************
\chapter{Apprendimento strutturale}
\label{cap:structurallearning}
%************************************************
Uno dei casi principali che costituisce il problema dell'\emph{apprendimento} di modelli grafico probabilistici è l'apprendimento della struttura incognita sottostante un modello, cioè la selezione di un modello probabilistico che rappresenti un dato \emph{\keyword{training set}}. %Anche se questo processo è spesso di elevata complessità, esso è considerato di elevata importanza in quanto la costruzione manuale di una struttura può essere difficile o addirittura impossibile se le variabili che la compongono sono sconosciute o di difficile caratterizzazione.

Il problema dell'\emph{apprendimento strutturale\index{apprendimento!strutturale}} da \emph{dati completi\index{dati!completi}} di una \acl{CTBN} (\acs{CTBN}) è l'argomento trattato in questo capitolo.

Questo problema può essere informalmente descritto nel seguente modo: dato un \emph{\keyword{training set}} composto da istanze di un insieme di variabili casuali si trovi un \keyword{grafo} che rappresenti le relazioni fra le variabili casuali evidenziate nei dati. %Si noti come tale problema possa essere catalogato come una forma di \keyword{apprendimento non supervisionato}; nel senso che il processo di apprendimento non distingue la variabile classe dalle variabili attributo nei dati.

L'obiettivo è quindi indurre una struttura (\ie{} \keyword{grafo}) che descriva nel miglior modo possibile la distribuzione di probabilità sui dati (\ie{} \emph{\keyword{training set}}). Si osservi, inoltre, che questo problema di \keyword{ottimizzazione} è \emph{$NP$-completo\index{$NP$-completo|see{complessità}}}\index{complessità!$NP$-completo} per le \acl{BN}~\citep{Chickering1994,Chickering2004}. Per questa ragione viene spesso trattato con algoritmi approssimati. %solitamente intrattabile per le \acl{BN}~\citep{Chickering1994,Chickering2004}, anche qualora si restringa la cardinalità massima dell'insieme dei genitori di ogni nodo.

Per quanto riguarda invece il caso delle \acs{CTBN}, \citet{Nodelman2002} hanno dimostrato che, grazie alla mancanza del vincolo di \keyword{aciclicità}, come già accennato nella \autoref{sec:ctbn-rappresentazione}, il problema dell'apprendimento strutturale di una \acs{CTBN} è significativamente più facile rispetto all'apprendimento strutturale di una \acl{BN}, o di modelli da esse derivanti (\eg{} le \acf{DBN}). Inoltre, nel caso si vincoli la procedura di ricerca a strutture con un numero massimo di genitori per nodo, questo problema può essere risolto in tempo\index{complessità!polinomiale} polinomiale\index{polinomiale|see{complessità}} rispetto al numero di nodi nella rete\footnote{Si noti comunque che il problema rimane esponenziale rispetto al numero massimo di genitori nella rete. Per tale motivo \citet{Stella2012} definiscono un classificatore bayesiano a tempo continuo.}

L'approccio che si presenta in questo capitolo è quindi un approccio basato sul punteggio\index{funzione di punteggio|see{score bayesiano}}: si definisce una funzione che computa uno \emph{\keyword{score bayesiano}} finalizzato alla valutazione di ogni struttura rispetto ai dati di addestramento\index{dati!addestramento, di|see{\trs{}}} (\ie{} \emph{\keyword{training set}}) e si usa una tecnica di \keyword{ricerca euristica} (\eg{} la ricerca \emph{\keyword{\hc{}}}) per cercare nello spazio delle strutture candidate quella che esibisce il maggior punteggio\index{funzione di punteggio|see{score bayesiano}}.

Si osservi che l'apprendimento dei parametri\index{apprendimento!parametri|see{stima}} (si veda la~\autoref{subsec:ctbn-params} \vpageref{subsec:ctbn-params}) è propedeutico per tale obiettivo poiché essi costituiscono la base dello \keyword{score bayesiano}.

\section{Funzione di scoring}\label{sec:ctbn-structurallearning-score}
Qualsiasi processo di apprendimento strutturale basato su punteggio\index{funzione di punteggio|see{score bayesiano}} è costituito da due componenti: una \emph{funzione di scoring\index{score bayesiano}} e una procedura di \keyword{ottimizzazione}.

L'obiettivo di questa sezione è quindi presentare una funzione di scoring\index{score bayesiano} per l'apprendimento strutturale delle \acl{CTBN} (\acs{CTBN}). Lo scopo di tale funzione è calcolare il punteggio\index{funzione di punteggio|see{score bayesiano}} (\ie{} lo \keyword{score bayesiano}) di una struttura relativamente al \emph{\keyword{training set}} $\conceptsym{D}$ fornito.

Si definisce lo \emph{\keyword{score bayesiano}} sul \keyword{grafo} $\conceptsym{G}$ di una \acs{CTBN} nel seguente modo:
\begin{equation}\label{eq:structurallearning-score}
score_B(\conceptsym{G}:\conceptsym{D})=\ln{P(\conceptsym{D}\,\arrowvert\,\conceptsym{G})} + \ln{P(\conceptsym{G})}
\end{equation}
Come mostra l'\autoref{eq:structurallearning-score} la funzione di scoring\index{score bayesiano} utilizza la probabilità a posteriori dell'insieme dei dati di apprendimento (\ie{} il \trs{} $\conceptsym{D}$) data la struttura candidata (\ie{} $\conceptsym{G}$), oltre alla probabilità a priori della struttura stessa.

\`E possibile aumentare in modo significativo l'efficienza dell'algoritmo di ricerca che si affronta nella prossima sezione qualora si facciano determinate assunzioni. Nello specifico, se si assume che la probabilità a priori della struttura, $P(\conceptsym{G})$, soddisfi la \emph{\keyword{structure modularity}}, ne consegue:
\begin{equation}\label{eq:structurallearning-prior-modularity}
P(\conceptsym{G})=\prod_{\setel{X}_i} P(Pa(\setel{X}_i) = Pa_{\conceptsym{G}}(\setel{X}_i))\text{.}
\end{equation}
Se si assume, inoltre, che la probabilità a priori dei parametri soddisfi la \emph{parameter modularity\index{parameter!modularity}}, allora per ogni due strutture $\conceptsym{G}$ e $\conceptsym{G}^\prime$ tali che $Pa_{\conceptsym{G}}(\setel{X}) = Pa_{\conceptsym{G}^\prime}(\setel{X})$ risulta:
\begin{equation}\label{eq:structurallearning-params-modularity}
P(\param{q}_{\setel{X}}\,,\param{$\theta$}_{\setel{X}}\,\arrowvert\,\conceptsym{G}) = P(\param{q}_{\setel{X}}\,,\param{$\theta$}_{\setel{X}}\,\arrowvert\,\conceptsym{G}^\prime)\text{.}
\end{equation}
Combinando l'assunzione di \emph{parameter independence\index{parameter!independence}} con l'equazione \ref{eq:structurallearning-params-modularity} derivante dalla \emph{parameter modularity\index{parameter!modularity}}, si ottiene:
\begin{align}\label{eq:structurallearning-params-posterior}
P(\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}\,\arrowvert\,\conceptsym{G}) &= \prod_{\setel{X}_i} \bigg[ P\Big(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}\,\arrowvert\,Pa(\setel{X}_i)=Pa_{\conceptsym{G}}(\setel{X}_i)\Big) \cdot \bigg.\nonumber\\
& \quad \bigg.{} \qquad \cdot P\Big(\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}\,\arrowvert\,Pa(\setel{X}_i)=Pa_{\conceptsym{G}}(\setel{X}_i)\Big) \bigg]\text{.}
\end{align}
Si osservi che, poiché la \emph{penalità del grafo\index{grafo!penalità, del}}, corrispondente al termine $P(Pa(\setel{X}_i) = Pa_{\conceptsym{G}}(\setel{X}_i))$ dell'\autoref{eq:structurallearning-prior-modularity}, è legata alla dimensione del \keyword{grafo} ma indipendente dalla quantità dei dati, è possibile ignorare il termine $P(\conceptsym{G})$ della funzione di scoring\index{score bayesiano} (\autoref{eq:structurallearning-score}).

Di conseguenza il termine significativo dell'\autoref{eq:structurallearning-score} è la \emph{likelihood marginale\index{likelihood!marginale}}, $P(\conceptsym{D}\,\arrowvert\,\conceptsym{G})$. Tale termine, infatti, codifica l'incertezza sui parametri integrando su tutti i possibili valori che essi possono assumere:
\begin{equation}\label{eq:structurallearning-marglikelihood}
P(\conceptsym{D}\,\arrowvert\,\conceptsym{G}) = \int_{\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}} P(\conceptsym{D}\,\arrowvert\,\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}) \, P(\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}\,\arrowvert\,\conceptsym{G}) \, d\param{q}_{\conceptsym{G}} d\param{$\theta$}_{\conceptsym{G}}\text{.}
\end{equation}
Come per l'\autoref{eq:ctbn-likelihood-decomp}, la likelihood marginale\index{likelihood!marginale} può essere decomposta come un prodotto di likelihood:
\begin{equation}\label{eq:structurallearning-marglikelihood-decomp}
\begin{split}
P(\conceptsym{D}\,\arrowvert\,\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}) &= \prod_{\setel{X}_i} L_{\setel{X}_i}(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D}) \, L_{\setel{X}_i}(\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D})\\
&= \underbrace{\bigg[\prod_{\setel{X}_i} L_{\setel{X}_i}(\param{q}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D}) \bigg]}_{L(\param{q}:\conceptsym{D})} \underbrace{\bigg[\prod_{\setel{X}_i} L_{\setel{X}_i}(\param{$\theta$}_{\setel{X}_i\,\arrowvert\,Pa(\setel{X}_i)}:\conceptsym{D}) \bigg]}_{L(\param{$\theta$}:\conceptsym{D})} \text{.}
\end{split}
\end{equation}
Combinando tale decomposizione con l'\emph{parameter independence\index{parameter!independence}} si può riformulare la likelihood marginale\index{likelihood!marginale} (\autoref{eq:structurallearning-marglikelihood}) nel seguente modo:
\begin{align}\label{eq:structurallearning-marglikelihood-decomp-2}
P(\conceptsym{D}\,\arrowvert\,\conceptsym{G}) &= \int_{\param{q}_{\conceptsym{G}}\,,\param{$\theta$}_{\conceptsym{G}}} L(\param{q}_{\conceptsym{G}}:\conceptsym{D}) L(\param{$\theta$}_{\conceptsym{G}}:\conceptsym{D}) P(\param{q}_{\conceptsym{G}}) P(\param{$\theta$}_{\conceptsym{G}}) \, d\param{q}_{\conceptsym{G}} d\param{$\theta$}_{\conceptsym{G}} \nonumber\\
&= \underbrace{\bigg[ \int_{\param{q}_{\conceptsym{G}}} L(\param{q}_{\conceptsym{G}}:\conceptsym{D}) P(\param{q}_{\conceptsym{G}}) \, d\param{q}_{\conceptsym{G}} \bigg]}_{\myterm{termQ}} \cdot \underbrace{\bigg[ \int_{\param{$\theta$}_{\conceptsym{G}}} L(\param{$\theta$}_{\conceptsym{G}}:\conceptsym{D}) P(\param{$\theta$}_{\conceptsym{G}}) \, d\param{$\theta$}_{\conceptsym{G}} \bigg]}_{\myterm{termT}} \text{.}
\end{align}
Ottenuta tale equazione, si affronta di seguito l'analisi e la decomposizione dei due termini che la compongono.

Utilizzando l'assunzione di \emph{local parameter independence\index{parameter!independence}}, il \autoref{termQ} dell'\autoref{eq:structurallearning-marglikelihood-decomp-2} è decomponibile nel seguente modo. Si noti che per brevità si pone $\setel{u}=pa_i(\setel{x})$.
\[
\prod_{\setel{X}_i} \prod_{\setel{u}} \prod_{\setel{x}} \int_0^\infty P(\param{q}_{\setel{x}\,\arrowvert\,\setel{u}}) \cdot L_{\setel{X}_i}(\param{q}_{\setel{x}\,\arrowvert\,\setel{u}}:\conceptsym{D}) \, d\param{q}_{\setel{x}\,\arrowvert\,\setel{u}} \tag*{\ref{termQ}} \text{.}
\]
Sostituendo a tale termine la distribuzione a \keyword{priori coniugata} su $\param{q}$ (si veda l'\autoref{eq:ctbn-bayesian-params-gamma}) e la likelihood delle quantità di tempo trascorse in ogni stato (si veda l'\autoref{eq:like-time-spent-in-each-state}) si ottiene: \\
\begin{align*}
\begin{split}
\prod_{\setel{X}_i} \prod_{\setel{u}} \prod_{\setel{x}} \int_0^\infty \Bigg( \frac{(\tau_{\setel{x}\arrowvert\setel{u}})^{\alpha_{\setel{x}\arrowvert\setel{u}}+1}}{\Gamma({\alpha_{\setel{x}\arrowvert\setel{u}}+1})} (\param{q}_{\setel{x}\arrowvert\setel{u}})^{\alpha_{\setel{x}\arrowvert\setel{u}}} e^{-\param{q}_{\setel{x}\arrowvert\setel{u}}\tau_{\setel{x}\arrowvert\setel{u}}} \; \cdot \\
\cdot \; (\param{q}_{x\arrowvert\setel{u}})^{\mstat{x\arrowvert\setel{u}}} e^{-\param{q}_{\setel{x}\arrowvert\setel{u}}\tstat{\setel{x}\arrowvert\setel{u}}} \Bigg) d\param{q}_{\setel{x}\arrowvert\setel{u}} \text{.}
\end{split}\tag*{\ref{termQ}}
\end{align*}

Si procede semplificando:
\[
\prod_{\setel{X}_i} \prod_{\setel{u}} \prod_{\setel{x}} \int_0^\infty \frac{(\tau_{\setel{x}\,\arrowvert\,\setel{u}})^{\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+1} \cdot (\param{q}_{\setel{x}\,\arrowvert\,\setel{u}})^{\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+\mstat{x\,\arrowvert\,\setel{u}}}}{\Gamma({\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+1}) \cdot e^{\param{q}_{\setel{x}\,\arrowvert\,\setel{u}}(\tau_{\setel{x}\,\arrowvert\,\setel{u}}+\tstat{\setel{x}\,\arrowvert\,\setel{u}})}}  \, d\param{q}_{\setel{x}\,\arrowvert\,\setel{u}} \tag*{\ref{termQ}} \text{.}
\]
E infine, risolvendo l'integrale, si ottiene:
\[
\prod_{\setel{X}_i} \underbrace{\prod_{\setel{u}} \prod_{\setel{x}} \frac{\Gamma(\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+\mstat{x\,\arrowvert\,\setel{u}}+1)(\tau_{\setel{x}\,\arrowvert\,\setel{u}})^{\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+1}}{\Gamma(\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+1)(\tau_{\setel{x}\,\arrowvert\,\setel{u}}+\tstat{\setel{x}\,\arrowvert\,\setel{u}})^{\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+\mstat{x\,\arrowvert\,\setel{u}}+1}}}_\text{$MargL^{\param{q}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D})$} \tag*{\ref{termQ}} \text{.}
\]
Relativamente all'analisi del \autoref{termT} dell'\autoref{eq:structurallearning-marglikelihood-decomp-2} si osservi che, poiché le distribuzioni sui parametri $\param{$\theta$}$ sono di \emph{Dirichlet\index{distribuzione!Dirichlet, di}}, tale operazione è analoga a quella comune per le \acl{BN}.

Ne consegue che il \autoref{termT} si semplifica:
\[
\prod_{\setel{X}_i} \underbrace{\prod_{\setel{u}} \prod_{\setel{x}} \frac{\Gamma(\alpha_{\setel{x}\,\arrowvert\,\setel{u}})}{\Gamma(\alpha_{\setel{x}\,\arrowvert\,\setel{u}}+\mstat{x\,\arrowvert\,\setel{u}})} \cdot \prod_{\setel{x}\neq\setel{x}^\prime} \frac{\Gamma(\alpha_{\setel{x}\setel{x}^\prime\,\arrowvert\,\setel{u}}+\mstat[x]{\setel{x}^\prime\,\arrowvert\,\setel{u}})}{\Gamma(\alpha_{\setel{x}\setel{x}^\prime\,\arrowvert\,\setel{u}})}}_\text{$MargL^{\param{$\theta$}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D})$} \tag*{\ref{termT}} \text{.}
\]
Quindi si può riformulare la likelihood marginale\index{likelihood!marginale}:\small
\begin{equation}\label{eq:data-given-graph}
P(\conceptsym{D}\,\arrowvert\,\conceptsym{G}) = \prod_{\setel{X}_i} MargL^{\param{q}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D}) \cdot MargL^{\param{$\theta$}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D}) \text{.}
\end{equation}\normalsize
Al fine di derivare la probabilità a priori della struttura (\autoref{eq:structurallearning-prior-modularity}) si è già assunto in precedenza che l'ipotesi di \emph{\keyword{structure modularity}} sussista. Perciò, sfruttando tale assunzione e combinando l'\autoref{eq:structurallearning-prior-modularity} della probabilità a priori della struttura con la likelihood marginale\index{likelihood!marginale} (\autoref{eq:data-given-graph}), si ottiene:
\begin{align}\label{eq:bayesian-score}
score_B(\conceptsym{G}:\conceptsym{D}) &= \sum_{\setel{X}_i} \bigg[ \ln{P(Pa(\setel{X}_i)=Pa_{\conceptsym{G}}(\setel{X}_i))} + \bigg.\nonumber\\
& \qquad \quad \> \bigg.{} + \ln{MargL^{\param{q}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D})} + \bigg.\nonumber\\
& \qquad \quad \> \bigg.{} + \ln{MargL^{\param{$\theta$}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D})} \bigg] = \nonumber\\
&= \sum_{\setel{X}_i} famscore_{\conceptsym{B}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D}) \text{.}
\end{align}
Si è quindi definita la funzione di scoring\index{score bayesiano} come una somma di score bayesiani, $famscore_{\conceptsym{B}}(\setel{X}_i\,,Pa_{\conceptsym{G}}(\setel{X}_i):\conceptsym{D})$, relativi ai nodi del \keyword{grafo} $\conceptsym{G}$. Ognuno di tali score bayesiani misura la qualità di $Pa_{\conceptsym{G}}(\setel{X}_i)$ come insieme dei nodi genitori di $\setel{X}_i$, dato l'insieme dei dati di apprendimento $\conceptsym{D}$.

\section{Ricerca della struttura}\index{ricerca della struttura}\label{sec:structurallearning-search}
In questa sezione si affronta il secondo passo del processo di apprendimento strutturale: l'utilizzo di una \emph{procedura di \keyword{ottimizzazione}} finalizzata alla ricerca di una struttura che massimizzi lo \emph{\keyword{score bayesiano}}.

~\citet{Chickering1994} ha mostrato come il problema di apprendere la struttura ottimale di una \acl{BN}, detto problema \emph{\keyword{k-learn}}, dove $k$ è il numero massimo di genitori per ogni variabile casuale, sia un problema \emph{$NP$-completo\index{complessità!$NP$-completo}} anche qualora si imponga $k=2$. La ragione di tale complessità è dovuta al vincolo di \keyword{aciclicità} delle \acs{BN} (\ie{} il grafo di una \acs{BN}, come da \autoref{defn:bn}, deve essere un \acs{DAG}): non è perciò possibile determinare l'insieme ottimale dei genitori di ogni nodo di una \acs{BN} individualmente; poiché la scelta di un insieme di genitori per un nodo restringe la possibilità di scelta relativa ai nodi restanti.

Come già accennato ed intuibile dalla composizione dello score bayesiano (si veda la funzione $famscore_{\conceptsym{B}}$, \autoref{eq:bayesian-score}), la ricerca della struttura ottimale di un modello \acl{CTBN} (\acs{CTBN}) è invece notevolmente più semplice rispetto a quello relativo alle \acs{BN} (o alle \acs{DBN}). La motivazione di tale vantaggio risiede nel fatto che, poiché gli archi fra i nodi del grado $\conceptsym{G}$ di una \acs{CTBN} rappresentano l'effetto nel tempo del valore attuale della variabile casuale padre sul valore futuro della variabile casuale figlia, non esiste un vincolo di \keyword{aciclicità} ed è di conseguenza possibile ottimizzare l'insieme dei nodi genitori di un qualsiasi nodo separatamente dagli altri.

Inoltre, qualora si restringa il massimo numero di genitori a un valore $k$, per ogni variabile casuale $\setel{X}_i$ di una \acs{CTBN}, con $i=1,\,\dotsc\,,N$, si può semplicemente enumerare ogni suo possibile insieme di nodi genitori $Pa(\setel{X}_i)$ tale che $\arrowvert Pa(\setel{X}_i) \arrowvert \leq k$ e calcolarne il rispettivo punteggio\index{funzione di punteggio|see{score bayesiano}} $famscore_{\conceptsym{B}}(\setel{X}_i\,,Pa(\setel{X}_i):\conceptsym{D})$. Infine scegliere come insieme dei nodi genitori di $\setel{X}_i$ quello con punteggio\index{funzione di punteggio|see{score bayesiano}} massimo.

%Si osservi che, fissato $k$, questa procedura di ricerca è \keyword{polinomiale} rispetto a $N$.
Si definisce perciò il seguente teorema~\citep{Nodelman2002}.
\begin{teorema}[Problema k-learn]
Il problema \textbf{k-learn} per le \acl{CTBN}, fissato $k$, può essere risolto in tempo polinomiale\index{complessità!polinomiale} rispetto al numero di variabili casuali $N$ e alla dimensione dell'insieme di dati $\conceptsym{D}$.
\end{teorema}

Si osservi che, fissando $k$ a priori, non è necessario enumerare esaustivamente tutti i possibili insiemi di nodi genitori di ogni nodo di una \acs{CTBN}. \'E quindi possibile utilizzare un algoritmo di \keyword{ricerca euristica} di tipo \emph{greedy} per esplorare lo spazio di ricerca. Nella~\autoref{subsec:structurallearning-hc} si presenta l'algoritmo scelto per l'apprendimento strutturale\index{apprendimento!strutturale} della struttura ottimale di un modello \acs{CTBN}.

\subsection{Hill Climbing}\label{subsec:structurallearning-hc}
L'algoritmo \emph{\keyword{\hc{}}} è una tecnica di \keyword{ricerca euristica} finalizzata alla risoluzione di problemi di ottimizzazione i cui stati (\ie{} elementi dello spazio di ricerca) contengono tutte le informazioni necessarie a costituire una soluzione~\citep{Russel2003}.

L'idea su cui si basa tale algoritmo consiste nell'iniziare la ricerca con una soluzione sub-ottimale e, nei passi successivi, migliorare iterativamente la soluzione, osservando gli stati vicini, finché una qualche condizione di fermata venga raggiunta (\eg{} l'algoritmo non può migliorare ulteriormente la soluzione corrente). Il processo di miglioramento è, come già accennato, basato sulla valutazione dello stato corrente tramite una funzione di punteggio\index{funzione di punteggio|see{score bayesiano}}.

A differenza di altri algoritmi di ricerca basati sul miglioramento iterativo della soluzione (\eg{} \emph{\keyword{simulated annealing}}, \emph{tabu search}), l'algoritmo \emph{\keyword{\hc{}}} si sposta sempre in uno stato che fornisce una soluzione con maggior punteggio~\citep{Russel2003}. L'utilizzo di tale algoritmo garantisce il raggiungimento di soluzioni localmente ottime (\ie{} soluzioni che non possono essere migliorate considerando solamente la configurazione degli stati vicini) in una quantità di tempo relativamente bassa. Tuttavia esso non garantisce il raggiungimento di una soluzione che costituisca l'ottimo globale, a meno che la funzione rappresentante lo spazio di ricerca non sia convessa. Ciò avviene poiché l'algoritmo smette di effettuare progressi verso la soluzione globalmente ottima nel momento in cui il vicinato della soluzione corrente non permette alcun miglioramento immediato.

Per sorpassare tale limitazione è possibile attuare varie strategie~\citep[si veda][]{Russel2003}, quali, ad esempio: l'esplorazione iterativa, a partire da diverse configurazioni iniziali, dello stesso spazio di ricerca (\ie{} \emph{random restart} \emph{\keyword{\hc{}}}); la selezione stocastica del vicinato da esaminare ad ogni passo della ricerca locale, sulla base della probabilità che un dato vicinato porti a un progresso maggiore rispetto ad altri vicinati; oppure la scelta di soluzioni non migliorative finalizzata ad una maggiore esplorazione dello spazio di ricerca (\ie{} \emph{simulated annealing}).

\begin{notas}
Questo algoritmo opera una gestione efficiente della memoria poiché non necessita il mantenimento di alcun albero di ricerca: esso conserva solamente l'informazione (\ie{} punteggio della soluzione) sullo stato corrente e quello successivo.
\end{notas}

L'\autoref{lst:hc-pseudo} illustra la tecnica di ricerca \emph{\keyword{\hc{}}} dato uno spazio degli stati discreto.
\vspace*{8pt}\begin{lstlisting}[language=pseudo, label=lst:hc-pseudo, caption={[Algoritmo \hc{}]Algoritmo \emph{\keyword{\hc{}}} per uno spazio degli stati discreto.}]
function hillclimbing(problem) {
    var current_state = start_state(problem)
    while (true) {
        var nb = neighbors(current_state)
        var next_eval = -inf
        var next_state = null
        for (x in nb) {
            var x_score = score(x)
            if (x_score <ls>$>$<le> next_eval) {
                next_state = x
                next_eval = x_score
            }
        }
        if (next_eval <ls>$\le$<le> score(current_state)) {
            break
        }
        current_state = next_state
    }
    return current_state
}
\end{lstlisting}

Di seguito si discute l'applicazione di tale algoritmo all'apprendimento strutturale\index{apprendimento!strutturale} delle \acs{CTBN}.

Come detto, a causa della mancanza del vincolo di aciclicità, è possibile eseguire la succitata procedura di ottimizzazione in modo indipendente per ogni singolo nodo del modello \acs{CTBN} in esame. Ciò permette di scomporre il problema dell'apprendimento strutturale\index{apprendimento!strutturale} in un insieme di problemi della stessa entità, di minore complessità e completamente indipendenti fra di essi; contesto ottimo per un approccio parallelizzato alla risoluzione del problema padre.

Dato uno qualsiasi dei succitati sotto-problemi, lo spazio degli stati che l'algoritmo \emph{\keyword{\hc{}}} può esplorare è composto da tutti i possibili insiemi di genitori con cardinalità minore o uguale a $k$, il numero massimo di genitori di ogni singolo nodo della \acs{CTBN}. L'algoritmo \emph{\keyword{\hc{}}} individua l'insieme di genitori ottimale per il nodo in esame, valutando, iterativamente, i possibili insiemi di nodi genitori con cardinalità minore e maggiore di $1$ rispetto alla cardinalità dell'insieme di genitori corrente. Si osservi che tale configurazione prevede che l'insieme dei genitori con cardinalità pari a $0$ (\ie{} insieme vuoto $\emptyset$) venga anch'esso valutato.

La funzione di \emph{scoring\index{score bayesiano}} con cui tali insiemi di genitori vengono valutati (funzione \lstinline[]|score|, \autoref{lst:hc-pseudo}) corrisponde alla funzione $famscore_{\conceptsym{B}}$, presentata nella~\vref{sec:ctbn-structurallearning-score}.

%--------------
%Because of this problem, a wealth of literature has been produced that seeks to understand and provide methods of learning structure from data. A fine example of an overview on the area was given by Buntine (1994, 1996), which although slightly dated now, is a good reference in dealing with most of the issues that arise in the area. Heckerman (1995b) gives a more tutorial like introduction to the task, and for a gradual introduction to the area, the recent book by Neapolitan (2004) has a good look at the theory behind a lot of the techniques used. To begin with, this section will start by examining the theory and complexity of learning Bayesian network structures and then move on to how the challenges have been addressed.
%--------------
%We argued above that the performance of a Bayesian network as a classifier may improve if the learning procedure takes into account the special status of the class variable. An easy way to ensure this is to bias the structure of the network, as in the naive Bayesian classifier, such that there is an edge from the class variable to each attribute. This ensures that, in the
% learned network, the probability P(C|A1,...,An) will take all attributes into account. (*)

%Accordingly, we limit our attention to a class of network structures that are based on the structure of naive Bayes, requiring that the class variable be a parent of every attribute.
%This ensures that, in the learned network, the probability Pr(C|A1,...,An), the main term determining the classification, will take every attribute into account. Unlike the naive Bayesian classifier, however, our classifier allows additional edges between attributes that capture correlations among them. This extension incurs additional computational costs. While the induction of the naive Bayesian classifier requires only simple bookkeeping, the induction of Bayesian networks requires searching the space of all possible networks— that is, the space of all possible combinations of edges.
