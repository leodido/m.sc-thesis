% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex
% !TEX spellcheck = it-IT

%************************************************
\chapter{Apprendimento strutturale}\label{cap:structurallearning}
%************************************************
Uno dei casi principali che costituisce il problema dell'\emph{apprendimento} di modelli grafico probabilistici è l'apprendimento della struttura incognita sottostante ogni modello.

Il problema dell'\emph{apprendimento \keywordsub[apprendimento]{strutturale}} da \emph{\keywordsub[apprendimento]{dati completi}} di una \acs{CTBN} è quindi l'argomento trattato in questo capitolo.

Generalmente, questo problema può essere informalmente descritto nel seguente modo: dato un \keywordsub[apprendimento]{training set} composto da istanze di un insieme di variabili casuali si trovi un grafo che rappresenti tali dati e le relazioni fra le variabili casuali. Si noti come tale problema possa essere catalogato come una forma di apprendimento non supervisionato; nel senso che il processo di apprendimento non distingue la variabile classe dalle variabili attributo nei dati. L'obiettivo è quindi indurre una struttura (\ie{} grafo) che descriva nel miglior modo possibile la distribuzione di probabilità sui dati (\ie{} \emph{\keywordsub[apprendimento]{training set}}). Si osservi, inoltre, che questo problema di ottimizzazione è solitamente intrattabile per le \acl{BN}~\citep{Chickering1994}. Tuttavia, imponendo alcuni vincoli sulle strutture delle \acs{BN} da includere nello spazio di ricerca, esistono algoritmi efficienti che risolvono tale problema in un tempo polinomiale rispetto al numero di variabili casuali rappresentate dalla struttura.

Per quanto riguarda invece il caso delle \acl{CTBN} (\acs{CTBN}), \citet{Nodelman2002} hanno dimostrato che, grazie alla mancanza del vincolo di aciclicità, come già accennato nella \autoref{sec:ctbn-rappresentazione}), il problema dell'apprendimento strutturale di una \acs{CTBN} è significatibamente più facile, sia teoricamente che in pratica, rispetto all'apprendimento strutturale di una \acl{BN}, o di modelli da esse derivanti, \eg{} le \acf{DBN}. Inoltre, nel caso si vincoli la procedura di ricerca a strutture con un numero massimo di genitori per nodo, questo problema può essere risolto in tempo polinomiale.

L'approccio che si presenta in questo capitolo è quindi un approccio basato sul punteggio: si definisce una funzione che computa uno \emph{\keywordsub[apprendimento]{score bayesiano}} finalizzato alla valutazione di ogni struttura rispetto ai dati di addestramento e si usa una tecnica di ricerca euristica (ad esempio, la ricerca \emph{\keyword{hill climbing}}) per cercare nello spazio delle strutture candidate quella che esibisce il maggior punteggio.

Si osservi che l'apprendimento dei parametri (si veda la \virgolette{\nameref{sec:ctbn-bayesian-estimate}}, \autoref{sec:ctbn-params}) è propedeutico per tale obiettivo poiché essi costituiscono la base dello \keywordsub[apprendimento]{score bayesiano}.

\cleardoublepage
\section{Funzione di scoring}\label{sec:ctbn-structurallearning-score}
Lo score bayesiano sul grafo $\conceptsym{G}$ di una \acs{CTBN} è definito nel seguente modo:
\begin{equation}\label{eq:structurallearning-score}
score_B(\conceptsym{G}:\conceptsym{D})=\ln{P(\conceptsym{D}\,\arrowvert\,\conceptsym{G})} + \ln{P(\conceptsym{G})}
\end{equation}
Come mostra l'\autoref{eq:structurallearning-score} la funzione di scoring utilizza la probabilità a posteriori dell’insieme dei dati di apprendimento (\ie{} il training set $\conceptsym{D}$) data la struttura candidata (\ie{} $\conceptsym{G}$).


\section{Ricerca della struttura}\label{sec:structurallearning-search}
\omissis{}

\subsection{Hill Climbing}\label{sec:structurallearning-hc}
\omissis{}

% TODO: 5.2 da Nodelman2007, paper Nodelman2002

% la mancanza di tale vincolo di aciclicità porta a notevoli vantaggi computazionali relativamente all’apprendimento della struttura di una CTBN dai dati.

% We argued above that the performance of a Bayesian network as a classifier may improve if the learning procedure takes into account the special status of the class variable. An easy way to ensure this is to bias the structure of the network, as in the naive Bayesian classifier, such that there is an edge from the class variable to each attribute. This ensures that, in the
% learned network, the probability P(C|A1,...,An) will take all attributes into account.

% Accordingly, we limit our attention to a class of network structures that are based on the structure of naive Bayes, requiring that the class variable be a parent of every attribute.
% This ensures that, in the learned network, the probability Pr(C|A1,...,An), the main term determining the classification, will take every attribute into account. Unlike the naive Bayesian classifier, however, our classifier allows additional edges between attributes that capture correlations among them. This extension incurs additional computational costs. While the induction of the naive Bayesian classifier requires only simple bookkeeping, the induction of Bayesian networks requires searching the space of all possible networks— that is, the space of all possible combinations of edges.

% SEM leaves unspecified the issue of how many greedy
% search steps one takes before recomputing the expected sufficient statistics and parameters. Nodelman et al. (2003) showed that, for CTBNs, structure search for a fixed number of parents per node can be done in polynomial time. Thus, it is possible, in this setting, to find the globally optimal structure given the current parametrization in the structure modification step. If one does this, SEM for CTBNs becomes an iterated optimization algorithm with a full maximization step for both structure and parameters.

% TODO: vedi Friedman1997, poi spiega il perché è così -> formula MDL -> mettere solo se anche il nostro score ha lo stesso problema
% This approach is justified by the asymptotic correctness of the Bayesian learning pro- cedure. Given a large data set, the learned network will be a close approximation for the probability distribution governing the domain (assuming that instances are sampled inde- pendently from a fixed distribution). Although this argument provides us with a sound theoretical basis, in practice we may encounter cases where the learning process returns a network with a relatively good MDL score that performs poorly as a classifier. To understand the possible discrepancy between good predictive accuracy and
