% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex
% !TEX spellcheck = it-IT

%************************************************
\chapter{\texorpdfstring{CTBN}{\ctbn{}}}
\label{cap:ctbn}
%************************************************
\acresetall
In questo capitolo si introducono i concetti fondamentali delle \ac{CTBN}, un framework utile a modellare i processi stocastici relativi a uno spazio degli stati che evolve nel tempo.
Tuttavia, prima di affrontare tale argomento si ritiene indispensabile presentare i suoi fondamenti matematici: le \ac{BN} e i \mprocess{}, trattati entrambi nella \autoref{sec:fondamenti}.

%************************************************
\section{Fondamenti}
\label{sec:fondamenti}
Come accennato, le \acl{CTBN} sviluppano e integrano concetti e idee provenienti da altre teorie afferenti l'area statistica e del machine learning. Al fine di conferire alla discussione sulle \acs{CTBN} un quadro iniziale completo ed esauriente, si presentano quindi gli aspetti di maggior rilievo di tali argomenti.
\begin{description}
\item[\bn{}] \hfill \\
Le \acl{CTBN} utilizzano una rappresentazione strutturata dello spazio degli stati propria della teoria delle \acl{BN}. Ne ereditano perciò gli aspetti chiave (\eg{} indipendenza condizionale) nonché l'insieme delle tecniche algoritmiche efficienti per l'apprendimento e l'inferenza.
\item[\mprocess{}] \hfill \\
Le \acl{CTBN} descrivono la dinamica evolutiva delle variabili casuali da cui sono costituite tramite un \omprocess{} globale, costituito da un insieme di \cmprocess{}.
\end{description} 

\subsection{\bn{}}
\label{sec:bn}
Una \acl{BN} è un modello grafico probabilistico costituito da un \acf{DAG}.\footnote{Un grafo aciclico diretto (anche detto grafo orientato aciclico o digrafo aciclico) è un tipo di grafo che non presenta cicli diretti: comunque si scelga un vertice non è possibile tornare ad esso percorrendo gli archi del grafo.} I nodi di tale grafo rappresentano un insieme di variabili casuali mentre gli archi rappresentano le dipendenze (e le indipendenze) condizionali fra esse. 
Una \acs{BN} rappresenta la distribuzione di probabilità congiunta del suo insieme di variabili casuali tramite la distribuzione di probabilità condizionale di ognuna di essa \eqref{eq:bn-chain-rule}.
Le \acs{BN} sono quindi modelli grafico probabilistici con cui è possibile modellare in modo probabilistico le relazioni causali dirette fra eventi. Perciò esse risultano molto utili nella rappresentazione e analisi di modelli del mondo reale che coinvolgono incertezza. Sono infatti usate in svariate applicazioni di supporto alle decisioni, bioinformatica, biologia computazionale, data mining, information retrieval e classificazione.

\subsubsection{Rappresentazione}
Di seguito si dà la definizione formale delle \acl{BN} e si introducono i loro aspetti basilari.

\begin{definizione}[\acl{BN}]
\label{defn:bn}
Una \acl{BN} $\conceptsym{B}$ è una coppia $\conceptsym{B}=(\conceptsym{G},\theta_{\conceptsym{G}})$ costituita da:
\begin{itemize}
    \item $\conceptsym{G}=(\set{V}(\conceptsym{G}),\set{A}(\conceptsym{G}))$, un \acl{DAG} dove:
    \begin{itemize}
        \item $\set{V}(\conceptsym{G})=\{\setel{V_1}, \dotsc, \setel{V_n}\}$ è l'insieme dei nodi, ognuno dei quali è associato con una \acf{CPD}\footnote{Nel caso di variabili causali discrete, le \acs{CPD} sono rappresentabili come delle tabelle che contengono i valori di probabilità di un nodo in funzione di tutte le possibili configurazioni dei nodi genitori (cioè l'insieme dei nodi da cui parte un arco che punta al nodo di interesse).}
        \label{defn:bn-markov-assumption}
        \item ogni nodo è condizionalmente indipendente (\ref{defn:ic}) dai suoi non--discendenti dati i suoi nodi genitori
        \item $\set{A}(\conceptsym{G})\subseteq\set{V}(\conceptsym{G})\times\set{V}(\conceptsym{G})$ è l'insieme degli archi fra i nodi $\set{V}(\conceptsym{G})$
    \end{itemize}
    \item $\theta_{\conceptsym{G}}$, insieme delle \acs{CPD} dei nodi che specifica $\set{P}_{\conceptsym{B}}$, la distribuzione di probabilità congiunta delle variabili casuali $\set{X}_{\set{V}(\conceptsym{G})}$ a cui corrispondono i nodi $\set{V}(\conceptsym{G})$.
\end{itemize}
\end{definizione}

La \acs{CPD} di ogni variabile casuale $\setel{X_i}\in\set{X}_{\set{V}(\conceptsym{G})}$ esprime i suoi valori di probabilità in funzione dei valori assunti da $pa(\setel{X_i})$, notazione con cui denotiamo l'\emph{insieme dei nodi genitori} per ogni nodo o variabile casuale.

Mentre un arco da un nodo genitore verso un nodo figlio di $\conceptsym{G}$ rappresenta una dipendenza condizionale fra le corrispettive variabili casuali, i nodi non connessi, invece, rappresentano variabili casuali condizionalmente indipendenti dagli altri nodi (per quanto riguarda il concetto di \emph{indipendenza condizionale} si rimanda invece a \ref{defn:ic}).

Prima di procedere con la discussione si introduce la Chain Rule, regola molto utile nel caso delle \acs{BN}.

\begin{teorema}[Chain Rule]
Dato un insieme di variabili casuali e una distribuzione di probabilità congiunta definita su di esse è possibile calcolare qualsiasi elemento di tale distribuzione tramite le distribuzioni di probabilità condizionale delle variabili casuali \cite{Russel2003}.
\end{teorema}

Perciò, dato un insieme di variabili casuali $\setel{A_1},\dotsc,\setel{A_n}$ è possibile calcolare il valore di tale membro della distribuzione di probabilità congiunta applicando la definizione di probabilità condizionale:
\[
\set{P}(\setel{A_1},\dotsc,\setel{A_n})=\set{P}(\setel{A_n}|\setel{A_{n-1}},\dotsc,\setel{A_1})\cdot\set{P}(\setel{A_{n-1}},\dotsc,\setel{A_1})
\]
Ripetendo tale processo per ogni termine finale si ottiene:
\begin{equation}
\label{eq:chain-rule}
\set{P}(\bigcap_{k=1}^{n}\setel{A_k})=\prod_{k=1}^{n}\set{P}(\setel{A_k}|\bigcap_{j=1}^{k-1}\setel{A_j})
\end{equation}

Applicando la \eqref{eq:chain-rule} alle \acl{BN} diciamo che la distribuzione di probabilità congiunta $\set{P}_{\conceptsym{B}}$ si \emph{fattorizza} rispetto al grafo $\conceptsym{G}$ se è possibile scrivere:
\begin{equation}
\label{eq:bn-chain-rule}
\set{P}_{\conceptsym{B}}(\setel{X_1}, \dotsc, \setel{X_n})=\prod_{i=1}^{n}\set{P}(\setel{X_i}|pa(\setel{X_i}))
\end{equation}
L'equazione \eqref{eq:bn-chain-rule} esprime quindi la \emph{proprietà di fattorizzazione} della distribuzione congiunta del modello grafico, ed è ciò che permette di descriverla efficientemente in funzione delle distribuzioni condizionali dei nodi. Si noti inoltre, che le \acl{BN} richiedono che la loro componente $\conceptsym{G}$ non contenga cicli (si veda \acs{DAG} in \ref{defn:bn}) affinché possano rispettare tale proprietà.

Poiché, come detto, una \acl{BN} stabilisce che ogni nodo, dati i suoi immediati ascendenti (i.e. nodi genitori), è \emph{condizionalmente indipendente} da ogni altro nodo che non sia un suo discendente, di seguito introduciamo tale concetto formalmente.
\begin{definizione}[Indipendenza condizionale]\label{defn:ic}
Un evento $\setel{A}$ è \emph{condizionalmente indipendente} da un evento $\setel{B}$, data l'evidenza su un evento $\setel{C}$, qualora la conoscenza di $\setel{B}$ non apporta alcuna variazione alla probabilità di $\setel{A}$ rispetto a quella conseguente alla conoscenza di $\setel{C}$.
Formalmente, ciò significa che:
\[
\set{P}(\setel{A},\setel{B}|\setel{C})=\set{P}(\setel{A}|\setel{B},\setel{C})\cdot\set{P}(\setel{B}|\setel{C})=\set{P}(\setel{A}|\setel{C})\cdot\set{P}(\setel{B}|\setel{C})
\]
Da cui segue che:
\[
\setel{A}\perp\setel{B}|\setel{C}\iff\set{P}(\setel{A}|\setel{B},\setel{C})=\set{P}(\setel{A}|\setel{C})
\]
\end{definizione}
In termini non formali, supponendo di essere nel caso della definizione, cioè di avere una variabile casuale $\setel{A}$ \emph{condizionalmente indipendente} da $\setel{B}$ dato $\setel{C}$, ciò significa che è possibile ignorare $\setel{B}$ poiché essa non ha alcun riflesso sulla distribuzione condizionale di $\setel{A}$.

Si noti che il concetto appena espresso gioca quindi un ruolo importante per i modelli probabilistici, quali sono le \acl{BN}: semplifica la struttura del modello e i calcoli richiesti per l'inferenza e l'apprendimento del modello. Le \acl{BN} ereditano questi benefici dell'indipendenza condizionale come conseguenza della loro definizione (si veda \ref{defn:bn-markov-assumption}): la distribuzione condizionale di ogni variabile casuale $\setel{X_i}$ dipende solo ed esclusivamente dal valore dei suoi genitori $pa(\setel{X_i})$ mentre ignora completamente le variabili casuali associate a nodi non--discendenti di $\setel{X_i}$. In breve:

$\forall$ $\setel{X_i}\in\set{X}_{\set{V}(\conceptsym{G})}$:
\[
\set{P}(\setel{X_i}|\setel{E},pa(\setel{X_i}))=\set{P}(\setel{X_i}|pa(\setel{X_i}))\;\forall\:\setel{E}\in nd(\setel{X_i})
\]
dove $nd(\setel{X_i})$ è l'insieme dei nodi non--discendenti (ed $\setel{E}$ è una variabile casuale o un insieme di variabili casuali ad essi associati).
In base a ciò si dice quindi che le \acl{BN} rispettano l'\emph{assunzione locale di Markov}.

\subsubsection{Apprendimento e Inferenza}\acresetall
In questa sezione si descrivono brevemente, e solo a scopo introduttivo, i processi di apprendimento e inferenza sulle \acl{BN}.

Il problema dell'apprendimento per le \acl{BN} si divide principalmente in due casi:
\begin{itemize}
    \item apprendere le \acs{CPD}, nota la struttura 
    \item apprendere sia le \acs{CPD}, sia la struttura (incognita).
\end{itemize}
In entrambi i casi è di grande aiuto la rappresentazione efficiente delle \acl{BN} che, tramite la \emph{fattorizzazione} della distribuzione di probabilità congiunta, permette di rappresentarla in modo compatto \eqref{eq:bn-chain-rule} riducendo notevolmente il numero di parametri da calcolare.

Come detto, per specificare completamente una \acl{BN} è necessario rappresentare completamente la distribuzione di probabilità congiunta delle sue variabili tramite la \acl{CPD} di ognuna di esse. In generale, tali distribuzioni condizionali possono avere una qualsiasi forma anche se, al fine di semplificare i calcoli, è comune utilizzare distribuzioni discrete o Gaussiane per modellarle. \`E frequente la situazione in cui queste distribuzioni condizionali includono parametri sconosciuti che è necessario stimare dai dati. In tali casi solitamente si procede tramite l'algoritmo di \acf{EM}, il quale alterna il calcolo dei valori attesi delle variabili casuali non osservate condizionalmente ai dati osservati con la massimizzazione della likelihood. Tale approccio generalmente converge ai valori di massima probabilità a posteriori per i parametri. Esistono comunque una varietà di altri approcci possibili (\eg{} trattare i parametri come variabili casuali sconosciute addizionali) per l'\emph{apprendimento dei parametri} che tuttavia non sono argomento di questo lavoro di tesi.

Si noti che le \acl{BN} non sono solamente un \emph{modello discriminativo ma anche generativo} poiché possono essere utilizzate per soddisfare query arbitrarie, cioè per effettuare \emph{inferenza probabilistica}: calcolare la distribuzione a posteriori di un insieme di variabili casuali data l'osservazione (evidenza) di altre (sfruttando il \emph{teorema di Bayes}). In letteratura sono stati esplorati molti metodi di \emph{inferenza esatta}, quali ad esempio l'eliminazione tramite integrazione o somma delle variabili non osservate che non fanno parte della query probabilistica o il metodo clique tree proprogation. Questi metodi, come gli altri presenti in letterature, sono esponenziali rispetto al tree-width del grafo. Per quanto riguarda invece gli algoritmi di \emph{inferenza approssimata} si citano due tra i più comuni: l'importance sampling e la simulazione \acf{MCMC}.

Quando si dispone del grafo sottostante una \acs{BN}, aldilà dell'osservabilità o meno delle sue variabili casuali, è possibile quindi usare tale \acs{BN} per effettuare inferenza. Nel caso in cui invece non si disponga della struttura di una \acs{BN} si presenta innanzitutto il problema dell'\emph{apprendimento strutturale}. Per apprendere automaticamente il grafo di una \acl{BN} sono stati sviluppati principalmente due famiglie di algoritmi:
\begin{itemize}
    \item algoritmi basati sulla ricerca dello scheletro del grafo dal quale, tramite le indipendenze condizionali osservate, si deducono successivamente le direzioni degli archi
    \item algoritmi che utilizzano tecniche di ricerca ottimizzata.
\end{itemize}
Gli algoritmi facenti parte della seconda famiglia utilizzando una strategia di ricerca (\eg{} Hill Climbing, Best First Search, Simulated Annealing) e una funzione di scoring. Solitamente la funzione di scoring utilizza la probabilità a posteriori della struttura in esame, dato l'insieme dei dati di apprendimento (\ie{} training set). Tuttavia, per quanto questi algoritmi siano utilizzati molto frequentemente, essi sono super esponenziali rispetto al numero di nodi della struttura del grafo. Inoltre, qualora si utilizzi una strategia di ricerca locale, è possibile che l'algoritmo restituisca come risultato un minimo locale (per evitare questa situazione si ricorre spesso a metodi di ricerca globale quali il \acs{MCMC}). Si fa notare che è possibile ridurre il tempo necessario richiesto per l'apprendimento strutturale fissando un numero massimo di genitori candidati e cercando esaustivamente in insiemi di tale cardinalità una struttura che massimizzi l'informazione mutua fra variabili.

\subsection{\mprocess{}}
\label{sec:mps}

Sempre al fine di preparare la discussione delle \acl{CTBN} si presentano di seguito concetti relativi ai Markov process.

\begin{definizione}[Proprietà di Markov]
\label{defn:markov-assumption}
% http://it.wikipedia.org/wiki/Propriet%C3%A0_di_Markov

Si descrive un modello per cui si assume sussista la proprietà di Markov come un modello che rispetta l'assunzione di Markov.
\end{definizione}

\begin{definizione}[\upcase\omprocess{}]
\label{defn:homogeneus-markov-provess}
\end{definizione} 

\begin{definizione}[Matrice di intensità]
\label{defn:im}
\end{definizione} 

\begin{definizione}[\upcase\cmprocess{}]
\label{defn:conditional-markov-provess}
\end{definizione} 

\begin{definizione}[Matrice di intensità condizionata]
\label{defn:cim}
\end{definizione} 

%************************************************
\section{Rappresentazione}
\label{sec:ctbn-rappresentazione}

Una \acl{CTBN} è un modello grafico in cui ogni nodo è associato con una variabile casuale i cui stati evolvono nel tempo continuo. Si assume perciò che tali dinamiche evolutive siano governate e dipendano dal valore che gli stati dei nodi padre assumono \cite{Stella2012}.
Una \acs{CTBN} è composta principalmente da due componenti:
\begin{itemize}
    \item una distribuzione di probabilità iniziale
    \item le dinamiche che regolano l'evoluzione nel tempo continuo della distribuzione di probabilità
\end{itemize}
Più formalmente si definisce:
\begin{definizione}[\acl{CTBN}]
Dato un insieme $\set{X}$ di variabili casuali $\setel{X_1}, \setel{X_2}, \dotsc, \setel{X_N}$ dove ogni $\setel{X_n}$ ha uno spazio degli stati finito $val(\setel{X_N})=\{ \vectel{x_1}, \dotsc, \vectel{x_J} \}$, una \acs{CTBN} $\conceptsym{N}$ su $\set{X}$ consiste di:
\begin{itemize}
    \item una distribuzione di probabilità iniziale $\priorsign{\set{X}}$ specificata come una \bn{} $\conceptsym{B}$ su $\set{X}$
    \item un modello di transizione continuo, specificato da:
    \begin{itemize}
        \item un grafo $\conceptsym{G}$, orientato e non necessariamente aciclico, composto dai nodi $\setel{X_1}, \setel{X_2}, \dotsc, \setel{X_N}$, ognuno dei quali possiede un insieme di genitori (possibilmente vuoto) denotato da $pa(\setel{X_n})$
        \item una matrice di intensità condizionale $\cimsign{\setel{X_n}}$ per ogni nodo $\setel{X_n} \in \set{X}$.
    \end{itemize}
\end{itemize}
\end{definizione}
\begin{nota}
Si noti che, diversamente dalle \acl{BN}, nelle \acl{CTBN} gli archi fra i nodi rappresentano le relazioni temporali fra essi. Tali relazioni codificano le dinamiche evolutive dei nodi, ognuna delle quali è espressa condizionatamente alla dinamica evolutiva degli stati dei suoi nodi genitori. Per tale motivo è possibile che la componente $\conceptsym{G}$ del modello di transizione continuo contenga dei cicli. Tra l'altro, come vedremo nel prosieguo, la mancanza di tale vincolo di aciclicità porta a notevoli vantaggi computazionali relativamente all'apprendimento della struttura di una \acs{CTBN} dai dati. 
\end{nota}

%************************************************
\section{Apprendimento}
\label{sec:ctbn-apprendimento}

%************************************************
\section{Inferenza}
\label{sec:ctbn-inferenza}


% TODO: apprendimento strutturale?
% TODO: inserire immagini esemplificative delle ctbn
